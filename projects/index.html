<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> projects | Sri Aditya Deevi </title> <meta name="author" content="Sri Aditya Deevi"> <meta name="description" content="Personal website of Sri Aditya Deevi. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%A4%96&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://dsriaditya999.github.io/projects/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Sri Aditya</span> Deevi </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/awards/">awards </a> </li> <li class="nav-item "> <a class="nav-link" href="/certifications/">certifications </a> </li> <li class="nav-item "> <a class="nav-link" href="/gallery/">gallery </a> </li> <li class="nav-item"> <a class="nav-link" href="/assets/pdf/SriAdityaDeevi_Resume_06Oct2025.pdf" target="_blank" rel="noopener noreferrer">cv <span class="sr-only">(current)</span> </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">projects</h1> <p class="post-description"></p> </header> <article> <style>.projects h2.category{color:var(--color-heading);margin-bottom:.5rem}</style> <div class="projects"> <a id="Graduate Projects" href=".#Graduate%20Projects"> <h2 class="category">Graduate Projects</h2> </a> <div class="row row-cols-1 row-cols-md-3"> <div class="col"> <a href="/projects/0_project/"> <div class="card hoverable" style="min-height: 400px; display: flex; flex-direction: column; justify-content: space-between; transition: transform 0.3s ease, box-shadow 0.3s ease;"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/robotics_I-480.webp 480w,/assets/img/publication_preview/robotics_I-800.webp 800w,/assets/img/publication_preview/robotics_I-1400.webp 1400w," sizes="250px" type="image/webp"></source> <img src="/assets/img/publication_preview/robotics_I.png" class="card-img-top" width="100%" height="auto" alt="project thumbnail" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="card-body p-2" style="flex-grow: 1; overflow: hidden;"> <h2 class="card-title" style="font-size: 1.15rem; margin-bottom: 0.5rem; display: -webkit-box; -webkit-line-clamp: 3; -webkit-box-orient: vertical; overflow: hidden; text-overflow: ellipsis;">Self Untangling Robotic Snake Arm with Dynamic Obstacle Avoidance</h2> <p class="card-text" style="font-size: 0.9rem; margin-bottom: 0.75rem; overflow: hidden; text-overflow: ellipsis; white-space: nowrap;"></p> <div class="row ml-1 mr-1 p-0 justify-content-between text-center" style="display: flex; justify-content: space-between;"> <div class="icon" data-toggle="tooltip" title="Code Repository" style="flex: 1;"> <a href="https://github.com/dsriaditya999/robotics_final_v2" class="text-decoration-none" style="color: inherit;" rel="external nofollow noopener" target="_blank"> <i class="fa-brands fa-github" style="font-size: 1.5rem;"></i> <div style="font-size: 0.75rem; color: inherit;">Code</div> </a> </div> <div class="icon" data-toggle="tooltip" title="Report" style="flex: 1;"> <a href="/assets/pdf/133a_Final_Report.pdf" class="text-decoration-none" style="color: inherit;"> <i class="fa-solid fa-file-pdf" style="font-size: 1.5rem;"></i> <div style="font-size: 0.75rem; color: inherit;">Report</div> </a> </div> <div class="icon" data-toggle="tooltip" title="Video" style="flex: 1;"> <a href="/assets/video/robotics_I_final.mp4" class="text-decoration-none" style="color: inherit;"> <i class="fa-solid fa-video" style="font-size: 1.5rem;"></i> <div style="font-size: 0.75rem; color: inherit;">Video</div> </a> </div> <div class="icon" data-toggle="tooltip" title="Abstract" style="flex: 1;"> <a href="#abstract-Self-Untangling-Robotic-Snake-Arm-with-Dynamic-Obstacle-Avoidance" data-toggle="collapse" role="button" aria-expanded="false" aria-controls="abstract-Self-Untangling-Robotic-Snake-Arm-with-Dynamic-Obstacle-Avoidance" class="text-decoration-none" style="color: inherit;"> <i class="fa-solid fa-file-alt" style="font-size: 1.5rem;"></i> <div style="font-size: 0.75rem; color: inherit;">Abstract</div> </a> </div> </div> <div class="collapse mt-2" id="abstract-Self-Untangling-Robotic-Snake-Arm-with-Dynamic-Obstacle-Avoidance"> <div class="card card-body p-2" style="border: 1px dashed #ccc; font-size: 0.85rem;"> This project aims to develop effective methods for a robotic snake arm to perform complex tasks such as obstacle avoidance, targeting and touching a random object (e.g., a colored cube) with precise gripper orientation, and untangling itself from knots. We considered a simulated environment in ROS2, where obstacles like rocks fall vertically, presenting dynamic challenges for the robotic arm. Through various experiments and extensive analysis across different robots and experimental scenarios, we sought to optimize the performance and versatility of the robotic snake arm in real-world applications. </div> </div> </div> </div> </a> </div> <a href="#" class="scroll-down-arrow" style="display: none;"> <i class="fa-solid fa-chevron-down"></i> </a> <style>.card:hover .card-img-top{transform:scale(1.1)}.card:hover{transform:translateY(-5px);box-shadow:0 10px 20px rgba(0,0,0,0.2)}.scroll-down-arrow{position:fixed;bottom:20px;left:20px;font-size:2rem;color:var(--color-text);background:var(--color-bg-secondary);border-radius:50%;padding:10px;z-index:1000;animation:float 1.5s ease-in-out infinite}@keyframes float{0%,100%{transform:translateY(0)}50%{transform:translateY(-10px)}}</style> <script>document.addEventListener("scroll",function(){const e=document.querySelector(".scroll-down-arrow"),o=document.documentElement.scrollHeight-window.innerHeight,n=window.scrollY;e.style.display=n>0&&n<o-50?"block":"none"}),document.querySelector(".scroll-down-arrow").addEventListener("click",function(e){e.preventDefault(),window.scrollBy({top:window.innerHeight,behavior:"smooth"})});</script> <div class="col"> <a href="/projects/1_project/"> <div class="card hoverable" style="min-height: 400px; display: flex; flex-direction: column; justify-content: space-between; transition: transform 0.3s ease, box-shadow 0.3s ease;"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/robotics_II-480.webp 480w,/assets/img/publication_preview/robotics_II-800.webp 800w,/assets/img/publication_preview/robotics_II-1400.webp 1400w," sizes="250px" type="image/webp"></source> <img src="/assets/img/publication_preview/robotics_II.png" class="card-img-top" width="100%" height="auto" alt="project thumbnail" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="card-body p-2" style="flex-grow: 1; overflow: hidden;"> <h2 class="card-title" style="font-size: 1.15rem; margin-bottom: 0.5rem; display: -webkit-box; -webkit-line-clamp: 3; -webkit-box-orient: vertical; overflow: hidden; text-overflow: ellipsis;">RRT Based Motion Planner for Non-Holonomic Mobile Robots</h2> <p class="card-text" style="font-size: 0.9rem; margin-bottom: 0.75rem; overflow: hidden; text-overflow: ellipsis; white-space: nowrap;"></p> <div class="row ml-1 mr-1 p-0 justify-content-between text-center" style="display: flex; justify-content: space-between;"> <div class="icon" data-toggle="tooltip" title="Code Repository" style="flex: 1;"> <a href="https://github.com/Claude0311/final133b" class="text-decoration-none" style="color: inherit;" rel="external nofollow noopener" target="_blank"> <i class="fa-brands fa-github" style="font-size: 1.5rem;"></i> <div style="font-size: 0.75rem; color: inherit;">Code</div> </a> </div> <div class="icon" data-toggle="tooltip" title="Report" style="flex: 1;"> <a href="/assets/pdf/133b_Final_Report_.pdf" class="text-decoration-none" style="color: inherit;"> <i class="fa-solid fa-file-pdf" style="font-size: 1.5rem;"></i> <div style="font-size: 0.75rem; color: inherit;">Report</div> </a> </div> <div class="icon" data-toggle="tooltip" title="Video" style="flex: 1;"> <a href="/assets/video/robotics_II_final.mp4" class="text-decoration-none" style="color: inherit;"> <i class="fa-solid fa-video" style="font-size: 1.5rem;"></i> <div style="font-size: 0.75rem; color: inherit;">Video</div> </a> </div> <div class="icon" data-toggle="tooltip" title="Abstract" style="flex: 1;"> <a href="#abstract-RRT-Based-Motion-Planner-for-Non-Holonomic-Mobile-Robots" data-toggle="collapse" role="button" aria-expanded="false" aria-controls="abstract-RRT-Based-Motion-Planner-for-Non-Holonomic-Mobile-Robots" class="text-decoration-none" style="color: inherit;"> <i class="fa-solid fa-file-alt" style="font-size: 1.5rem;"></i> <div style="font-size: 0.75rem; color: inherit;">Abstract</div> </a> </div> </div> <div class="collapse mt-2" id="abstract-RRT-Based-Motion-Planner-for-Non-Holonomic-Mobile-Robots"> <div class="card card-body p-2" style="border: 1px dashed #ccc; font-size: 0.85rem;"> The project focuses on developing motion planning methods for non-holonomic mobile robots, specifically wheeled systems like cars, using Rapidly-exploring Random Tree (RRT) based algorithms. The objective was to create a planner capable of efficiently and effectively navigating through complex environments, avoiding obstacles in challenging scenarios such as narrow garages, parallel parking, and tight streets. Through a series of experiments, we tested the planner's performance and derived insightful inferences from our analyses, supported by compelling graphical results and visual stills. </div> </div> </div> </div> </a> </div> <a href="#" class="scroll-down-arrow" style="display: none;"> <i class="fa-solid fa-chevron-down"></i> </a> <style>.card:hover .card-img-top{transform:scale(1.1)}.card:hover{transform:translateY(-5px);box-shadow:0 10px 20px rgba(0,0,0,0.2)}.scroll-down-arrow{position:fixed;bottom:20px;left:20px;font-size:2rem;color:var(--color-text);background:var(--color-bg-secondary);border-radius:50%;padding:10px;z-index:1000;animation:float 1.5s ease-in-out infinite}@keyframes float{0%,100%{transform:translateY(0)}50%{transform:translateY(-10px)}}</style> <script>document.addEventListener("scroll",function(){const e=document.querySelector(".scroll-down-arrow"),o=document.documentElement.scrollHeight-window.innerHeight,n=window.scrollY;e.style.display=n>0&&n<o-50?"block":"none"}),document.querySelector(".scroll-down-arrow").addEventListener("click",function(e){e.preventDefault(),window.scrollBy({top:window.innerHeight,behavior:"smooth"})});</script> <div class="col"> <a href="/projects/2_project/"> <div class="card hoverable" style="min-height: 400px; display: flex; flex-direction: column; justify-content: space-between; transition: transform 0.3s ease, box-shadow 0.3s ease;"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/mobile-480.webp 480w,/assets/img/publication_preview/mobile-800.webp 800w,/assets/img/publication_preview/mobile-1400.webp 1400w," sizes="250px" type="image/webp"></source> <img src="/assets/img/publication_preview/mobile.png" class="card-img-top" width="100%" height="auto" alt="project thumbnail" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="card-body p-2" style="flex-grow: 1; overflow: hidden;"> <h2 class="card-title" style="font-size: 1.15rem; margin-bottom: 0.5rem; display: -webkit-box; -webkit-line-clamp: 3; -webkit-box-orient: vertical; overflow: hidden; text-overflow: ellipsis;">Non Holonomic RRT with Dynamic Replanning and Obstacle Mapping</h2> <p class="card-text" style="font-size: 0.9rem; margin-bottom: 0.75rem; overflow: hidden; text-overflow: ellipsis; white-space: nowrap;"></p> <div class="row ml-1 mr-1 p-0 justify-content-between text-center" style="display: flex; justify-content: space-between;"> <div class="icon" data-toggle="tooltip" title="Report" style="flex: 1;"> <a href="/assets/pdf/169_Final_Report.pdf" class="text-decoration-none" style="color: inherit;"> <i class="fa-solid fa-file-pdf" style="font-size: 1.5rem;"></i> <div style="font-size: 0.75rem; color: inherit;">Report</div> </a> </div> <div class="icon" data-toggle="tooltip" title="Video" style="flex: 1;"> <a href="/assets/video/169_Final_Video.mp4" class="text-decoration-none" style="color: inherit;"> <i class="fa-solid fa-video" style="font-size: 1.5rem;"></i> <div style="font-size: 0.75rem; color: inherit;">Video</div> </a> </div> <div class="icon" data-toggle="tooltip" title="Abstract" style="flex: 1;"> <a href="#abstract-Non-Holonomic-RRT-with-Dynamic-Replanning-and-Obstacle-Mapping" data-toggle="collapse" role="button" aria-expanded="false" aria-controls="abstract-Non-Holonomic-RRT-with-Dynamic-Replanning-and-Obstacle-Mapping" class="text-decoration-none" style="color: inherit;"> <i class="fa-solid fa-file-alt" style="font-size: 1.5rem;"></i> <div style="font-size: 0.75rem; color: inherit;">Abstract</div> </a> </div> </div> <div class="collapse mt-2" id="abstract-Non-Holonomic-RRT-with-Dynamic-Replanning-and-Obstacle-Mapping"> <div class="card card-body p-2" style="border: 1px dashed #ccc; font-size: 0.85rem;"> This project aims to develop a real mobile robot (Raspberry Pi based) with advanced capabilities, including initial global localization using Monte Carlo Localization, smooth car-like driving, and efficient path planning through narrow and complex areas. The robot can detect and avoid new obstacles, dynamically update an "Obstacle Map," and replan its path. Utilizing RRT-based motion planners for non-holonomic robots, the project focuses on two-wheeled systems like cars and car-trailer combinations. These planners generate raw paths refined through post-processing for smooth, collision-free navigation. Experiments and analyses show the non-holonomic RRT algorithm's effectiveness, which can ehnace autonomous navigation in challenging environments for applications such as smart cars and planetary rovers. </div> </div> </div> </div> </a> </div> <a href="#" class="scroll-down-arrow" style="display: none;"> <i class="fa-solid fa-chevron-down"></i> </a> <style>.card:hover .card-img-top{transform:scale(1.1)}.card:hover{transform:translateY(-5px);box-shadow:0 10px 20px rgba(0,0,0,0.2)}.scroll-down-arrow{position:fixed;bottom:20px;left:20px;font-size:2rem;color:var(--color-text);background:var(--color-bg-secondary);border-radius:50%;padding:10px;z-index:1000;animation:float 1.5s ease-in-out infinite}@keyframes float{0%,100%{transform:translateY(0)}50%{transform:translateY(-10px)}}</style> <script>document.addEventListener("scroll",function(){const e=document.querySelector(".scroll-down-arrow"),o=document.documentElement.scrollHeight-window.innerHeight,n=window.scrollY;e.style.display=n>0&&n<o-50?"block":"none"}),document.querySelector(".scroll-down-arrow").addEventListener("click",function(e){e.preventDefault(),window.scrollBy({top:window.innerHeight,behavior:"smooth"})});</script> <div class="col"> <a href="/projects/2_project_1/"> <div class="card hoverable" style="min-height: 400px; display: flex; flex-direction: column; justify-content: space-between; transition: transform 0.3s ease, box-shadow 0.3s ease;"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/gs_laser-480.webp 480w,/assets/img/publication_preview/gs_laser-800.webp 800w,/assets/img/publication_preview/gs_laser-1400.webp 1400w," sizes="250px" type="image/webp"></source> <img src="/assets/img/publication_preview/gs_laser.png" class="card-img-top" width="100%" height="auto" alt="project thumbnail" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="card-body p-2" style="flex-grow: 1; overflow: hidden;"> <h2 class="card-title" style="font-size: 1.15rem; margin-bottom: 0.5rem; display: -webkit-box; -webkit-line-clamp: 3; -webkit-box-orient: vertical; overflow: hidden; text-overflow: ellipsis;">Atmospheric Parameter Forecasting for Optical Channel Characterization</h2> <p class="card-text" style="font-size: 0.9rem; margin-bottom: 0.75rem; overflow: hidden; text-overflow: ellipsis; white-space: nowrap;"></p> <div class="row ml-1 mr-1 p-0 justify-content-between text-center" style="display: flex; justify-content: space-between;"> <div class="icon" data-toggle="tooltip" title="Abstract" style="flex: 1;"> <a href="#abstract-Atmospheric-Parameter-Forecasting-for-Optical-Channel-Characterization" data-toggle="collapse" role="button" aria-expanded="false" aria-controls="abstract-Atmospheric-Parameter-Forecasting-for-Optical-Channel-Characterization" class="text-decoration-none" style="color: inherit;"> <i class="fa-solid fa-file-alt" style="font-size: 1.5rem;"></i> <div style="font-size: 0.75rem; color: inherit;">Abstract</div> </a> </div> </div> <div class="collapse mt-2" id="abstract-Atmospheric-Parameter-Forecasting-for-Optical-Channel-Characterization"> <div class="card card-body p-2" style="border: 1px dashed #ccc; font-size: 0.85rem;"> This project aimed to enhance optical communication by forecasting atmospheric parameters. The focus was on two main tasks - Weather Forecasting and Predicting Atmospheric Coherence Length (r0). For Weather Forecasting, a sequence-to-sequence approach was used to predict temperature, air pressure, relative humidity, and wind speed at JPL weather stations. A GRU model achieved a 25% reduction in prediction errors for temperature and pressure, while more complex architectures were used for wind speed and humidity. Predicting r0 was challenging due to its high variability, but a hybrid approach combining analytically predicted r0 with a simple GRU model improved nowcasting accuracy. The best models were deployed for live weather forecasting at JPL stations, demonstrating their practical applicability. </div> </div> </div> </div> </a> </div> <a href="#" class="scroll-down-arrow" style="display: none;"> <i class="fa-solid fa-chevron-down"></i> </a> <style>.card:hover .card-img-top{transform:scale(1.1)}.card:hover{transform:translateY(-5px);box-shadow:0 10px 20px rgba(0,0,0,0.2)}.scroll-down-arrow{position:fixed;bottom:20px;left:20px;font-size:2rem;color:var(--color-text);background:var(--color-bg-secondary);border-radius:50%;padding:10px;z-index:1000;animation:float 1.5s ease-in-out infinite}@keyframes float{0%,100%{transform:translateY(0)}50%{transform:translateY(-10px)}}</style> <script>document.addEventListener("scroll",function(){const e=document.querySelector(".scroll-down-arrow"),o=document.documentElement.scrollHeight-window.innerHeight,n=window.scrollY;e.style.display=n>0&&n<o-50?"block":"none"}),document.querySelector(".scroll-down-arrow").addEventListener("click",function(e){e.preventDefault(),window.scrollBy({top:window.innerHeight,behavior:"smooth"})});</script> <div class="col"> <a href="https://openaccess.thecvf.com/content/WACV2024/papers/Deevi_RGB-X_Object_Detection_via_Scene-Specific_Fusion_Modules_WACV_2024_paper.pdf" rel="external nofollow noopener" target="_blank"> <div class="card hoverable" style="min-height: 400px; display: flex; flex-direction: column; justify-content: space-between; transition: transform 0.3s ease, box-shadow 0.3s ease;"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/rgb-x-object-detection-480.webp 480w,/assets/img/rgb-x-object-detection-800.webp 800w,/assets/img/rgb-x-object-detection-1400.webp 1400w," sizes="250px" type="image/webp"></source> <img src="/assets/img/rgb-x-object-detection.png" class="card-img-top" width="100%" height="auto" alt="project thumbnail" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="card-body p-2" style="flex-grow: 1; overflow: hidden;"> <h2 class="card-title" style="font-size: 1.15rem; margin-bottom: 0.5rem; display: -webkit-box; -webkit-line-clamp: 3; -webkit-box-orient: vertical; overflow: hidden; text-overflow: ellipsis;">RGB-X Object Detection via Scene-Specific Fusion Modules</h2> <p class="card-text" style="font-size: 0.9rem; margin-bottom: 0.75rem; overflow: hidden; text-overflow: ellipsis; white-space: nowrap;"></p> <div class="row ml-1 mr-1 p-0 justify-content-between text-center" style="display: flex; justify-content: space-between;"> <div class="icon" data-toggle="tooltip" title="Code Repository" style="flex: 1;"> <a href="https://github.com/dsriaditya999/RGBXFusion" class="text-decoration-none" style="color: inherit;" rel="external nofollow noopener" target="_blank"> <i class="fa-brands fa-github" style="font-size: 1.5rem;"></i> <div style="font-size: 0.75rem; color: inherit;">Code</div> </a> </div> <div class="icon" data-toggle="tooltip" title="Post" style="flex: 1;"> <a href="https://www.eas.caltech.edu/news/a-more-adaptive-approach-to-autonomous-vehicle-object-detection" class="text-decoration-none" style="color: inherit;" rel="external nofollow noopener" target="_blank"> <i class="fa-solid fa-blog" style="font-size: 1.5rem;"></i> <div style="font-size: 0.75rem; color: inherit;">Post</div> </a> </div> <div class="icon" data-toggle="tooltip" title="Slides" style="flex: 1;"> <a href="/assets/pdf/wacv_rgbx_video.pdf" class="text-decoration-none" style="color: inherit;"> <i class="fa-solid fa-file-powerpoint" style="font-size: 1.5rem;"></i> <div style="font-size: 0.75rem; color: inherit;">Slides</div> </a> </div> <div class="icon" data-toggle="tooltip" title="Abstract" style="flex: 1;"> <a href="#abstract-RGB-X-Object-Detection-via-Scene-Specific-Fusion-Modules" data-toggle="collapse" role="button" aria-expanded="false" aria-controls="abstract-RGB-X-Object-Detection-via-Scene-Specific-Fusion-Modules" class="text-decoration-none" style="color: inherit;"> <i class="fa-solid fa-file-alt" style="font-size: 1.5rem;"></i> <div style="font-size: 0.75rem; color: inherit;">Abstract</div> </a> </div> </div> <div class="collapse mt-2" id="abstract-RGB-X-Object-Detection-via-Scene-Specific-Fusion-Modules"> <div class="card card-body p-2" style="border: 1px dashed #ccc; font-size: 0.85rem;"> Multimodal deep sensor fusion has the potential to enable autonomous vehicles to visually understand their surrounding environments in all weather conditions. However, existing deep sensor fusion methods usually employ convoluted architectures with intermingled multimodal features, requiring large coregistered multimodal datasets for training. In this work, we present an efficient and modular RGB-X fusion network that can leverage and fuse pretrained single-modal models via scene-specific fusion modules, thereby enabling joint input-adaptive network architectures to be created using small, coregistered multimodal datasets. Our experiments demonstrate the superiority of our method compared to existing works on RGB-thermal and RGB-gated datasets, performing fusion using only a small amount of additional parameters. Our code is available at https://github.com/dsriaditya999/RGBXFusion. </div> </div> </div> </div> </a> </div> <a href="#" class="scroll-down-arrow" style="display: none;"> <i class="fa-solid fa-chevron-down"></i> </a> <style>.card:hover .card-img-top{transform:scale(1.1)}.card:hover{transform:translateY(-5px);box-shadow:0 10px 20px rgba(0,0,0,0.2)}.scroll-down-arrow{position:fixed;bottom:20px;left:20px;font-size:2rem;color:var(--color-text);background:var(--color-bg-secondary);border-radius:50%;padding:10px;z-index:1000;animation:float 1.5s ease-in-out infinite}@keyframes float{0%,100%{transform:translateY(0)}50%{transform:translateY(-10px)}}</style> <script>document.addEventListener("scroll",function(){const e=document.querySelector(".scroll-down-arrow"),o=document.documentElement.scrollHeight-window.innerHeight,n=window.scrollY;e.style.display=n>0&&n<o-50?"block":"none"}),document.querySelector(".scroll-down-arrow").addEventListener("click",function(e){e.preventDefault(),window.scrollBy({top:window.innerHeight,behavior:"smooth"})});</script> </div> <a id="Undergraduate Thesis Project" href=".#Undergraduate%20Thesis%20Project"> <h2 class="category">Undergraduate Thesis Project</h2> </a> <div class="row row-cols-1 row-cols-md-3"> <div class="col"> <a href="/projects/4_project/"> <div class="card hoverable" style="min-height: 400px; display: flex; flex-direction: column; justify-content: space-between; transition: transform 0.3s ease, box-shadow 0.3s ease;"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/arg-480.webp 480w,/assets/img/publication_preview/arg-800.webp 800w,/assets/img/publication_preview/arg-1400.webp 1400w," sizes="250px" type="image/webp"></source> <img src="/assets/img/publication_preview/arg.png" class="card-img-top" width="100%" height="auto" alt="project thumbnail" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="card-body p-2" style="flex-grow: 1; overflow: hidden;"> <h2 class="card-title" style="font-size: 1.15rem; margin-bottom: 0.5rem; display: -webkit-box; -webkit-line-clamp: 3; -webkit-box-orient: vertical; overflow: hidden; text-overflow: ellipsis;">Autonomous Robotic Grasping</h2> <p class="card-text" style="font-size: 0.9rem; margin-bottom: 0.75rem; overflow: hidden; text-overflow: ellipsis; white-space: nowrap;"></p> <div class="row ml-1 mr-1 p-0 justify-content-between text-center" style="display: flex; justify-content: space-between;"> <div class="icon" data-toggle="tooltip" title="Report" style="flex: 1;"> <a href="/assets/pdf/arg_final_report.pdf" class="text-decoration-none" style="color: inherit;"> <i class="fa-solid fa-file-pdf" style="font-size: 1.5rem;"></i> <div style="font-size: 0.75rem; color: inherit;">Report</div> </a> </div> <div class="icon" data-toggle="tooltip" title="Video" style="flex: 1;"> <a href="/assets/video/arg_final.mp4" class="text-decoration-none" style="color: inherit;"> <i class="fa-solid fa-video" style="font-size: 1.5rem;"></i> <div style="font-size: 0.75rem; color: inherit;">Video</div> </a> </div> <div class="icon" data-toggle="tooltip" title="Slides" style="flex: 1;"> <a href="/assets/pdf/arg_ppt.pdf" class="text-decoration-none" style="color: inherit;"> <i class="fa-solid fa-file-powerpoint" style="font-size: 1.5rem;"></i> <div style="font-size: 0.75rem; color: inherit;">Slides</div> </a> </div> <div class="icon" data-toggle="tooltip" title="Abstract" style="flex: 1;"> <a href="#abstract-Autonomous-Robotic-Grasping" data-toggle="collapse" role="button" aria-expanded="false" aria-controls="abstract-Autonomous-Robotic-Grasping" class="text-decoration-none" style="color: inherit;"> <i class="fa-solid fa-file-alt" style="font-size: 1.5rem;"></i> <div style="font-size: 0.75rem; color: inherit;">Abstract</div> </a> </div> </div> <div class="collapse mt-2" id="abstract-Autonomous-Robotic-Grasping"> <div class="card card-body p-2" style="border: 1px dashed #ccc; font-size: 0.85rem;"> Autonomous Robotic Grasping (ARG) is key to attaining the promise of intelligent robotics. The primary premise underlying vision-based ARG is the capacity of a robot to “perceive" its surroundings using vision sensors to constructively interact with various objects to accomplish a given task of interest. However, the real world consists of many highly variable aspects. It is neither tractable nor feasible for a robot to accurately represent its surroundings, the things in it, and the complex interactions among them. Therefore, learning is crucial in such intelligent autonomous systems to acquire the ability to perform skilled manipulation tasks. Effective ARG systems have many applications in various domains. They can be deployed in industries, spacecraft, restaurants, and homes to perform or assist human experts in performing versatile and repetitive manipulation tasks. In this project, the following two challenging ARG tasks (Objectives) are considered which are almost ubiquitously found problems that an intelligent robotic arm can automate =&gt; Task I - Grasping Various Objects in Diverse Environments and Task II - Dynamic Grasping of Moving Objects. In addition, the basic steps and tasks necessary for performing complex ARG tasks in a “real” robotic setup are taken into account as a part of the problem statement of this work. </div> </div> </div> </div> </a> </div> <a href="#" class="scroll-down-arrow" style="display: none;"> <i class="fa-solid fa-chevron-down"></i> </a> <style>.card:hover .card-img-top{transform:scale(1.1)}.card:hover{transform:translateY(-5px);box-shadow:0 10px 20px rgba(0,0,0,0.2)}.scroll-down-arrow{position:fixed;bottom:20px;left:20px;font-size:2rem;color:var(--color-text);background:var(--color-bg-secondary);border-radius:50%;padding:10px;z-index:1000;animation:float 1.5s ease-in-out infinite}@keyframes float{0%,100%{transform:translateY(0)}50%{transform:translateY(-10px)}}</style> <script>document.addEventListener("scroll",function(){const e=document.querySelector(".scroll-down-arrow"),o=document.documentElement.scrollHeight-window.innerHeight,n=window.scrollY;e.style.display=n>0&&n<o-50?"block":"none"}),document.querySelector(".scroll-down-arrow").addEventListener("click",function(e){e.preventDefault(),window.scrollBy({top:window.innerHeight,behavior:"smooth"})});</script> </div> <a id="Undergraduate Projects" href=".#Undergraduate%20Projects"> <h2 class="category">Undergraduate Projects</h2> </a> <div class="row row-cols-1 row-cols-md-3"> <div class="col"> <a href="https://easychair.org/publications/preprint/6hNw/open" rel="external nofollow noopener" target="_blank"> <div class="card hoverable" style="min-height: 400px; display: flex; flex-direction: column; justify-content: space-between; transition: transform 0.3s ease, box-shadow 0.3s ease;"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/nas-480.webp 480w,/assets/img/publication_preview/nas-800.webp 800w,/assets/img/publication_preview/nas-1400.webp 1400w," sizes="250px" type="image/webp"></source> <img src="/assets/img/publication_preview/nas.png" class="card-img-top" width="100%" height="auto" alt="project thumbnail" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="card-body p-2" style="flex-grow: 1; overflow: hidden;"> <h2 class="card-title" style="font-size: 1.15rem; margin-bottom: 0.5rem; display: -webkit-box; -webkit-line-clamp: 3; -webkit-box-orient: vertical; overflow: hidden; text-overflow: ellipsis;">Efficient Self-Supervised Neural Architecture Search</h2> <p class="card-text" style="font-size: 0.9rem; margin-bottom: 0.75rem; overflow: hidden; text-overflow: ellipsis; white-space: nowrap;"></p> <div class="row ml-1 mr-1 p-0 justify-content-between text-center" style="display: flex; justify-content: space-between;"> <div class="icon" data-toggle="tooltip" title="Slides" style="flex: 1;"> <a href="/assets/pdf/imcom_essnas.pdf" class="text-decoration-none" style="color: inherit;"> <i class="fa-solid fa-file-powerpoint" style="font-size: 1.5rem;"></i> <div style="font-size: 0.75rem; color: inherit;">Slides</div> </a> </div> <div class="icon" data-toggle="tooltip" title="Abstract" style="flex: 1;"> <a href="#abstract-Efficient-Self-Supervised-Neural-Architecture-Search" data-toggle="collapse" role="button" aria-expanded="false" aria-controls="abstract-Efficient-Self-Supervised-Neural-Architecture-Search" class="text-decoration-none" style="color: inherit;"> <i class="fa-solid fa-file-alt" style="font-size: 1.5rem;"></i> <div style="font-size: 0.75rem; color: inherit;">Abstract</div> </a> </div> </div> <div class="collapse mt-2" id="abstract-Efficient-Self-Supervised-Neural-Architecture-Search"> <div class="card card-body p-2" style="border: 1px dashed #ccc; font-size: 0.85rem;"> Deep Neural Networks (DNNs) have successfully demonstrated superior performance on many tasks across multiple domains. Their success is made possible by expert practitioners' careful design of neural architectures. This manual handcrafted design requires a colossal number of computational resources, time, and memory to arrive at an optimal architecture. Automated Neural Architecture Search (NAS) is a promising area to explore to overcome these issues. However, optimizing a network for a job is a tedious task that requires lengthy search time, high processor needs, and a thorough examination of enormous possibilities. The need of the hour is to develop a strategy that saves time while maintaining an excellent level of accuracy. In this paper, we design, explore, and experiment with various differentiable NAS methods which are memory, time, and compute efficient. We also explore the role and efficacy of self-supervision to guide the search for optimal architectures. Self-supervision offers numerous advantages such as facilitating the use of unlabelled data and making the “learning” non-task specific, thereby improving transfer to other tasks. To study the inclusion of self-supervision into the search process, we propose a simple loss function consisting of a convex combination of supervised cross-entropy loss and self-supervision loss. In addition, we carried out various analyses to characterize the performance of different approaches considered in this paper. The inspection of results obtained from various experiments on CIFAR-10 reveals that the proposed methodology balances time and accuracy while staying as near as possible to the state-of-the-art results. </div> </div> </div> </div> </a> </div> <a href="#" class="scroll-down-arrow" style="display: none;"> <i class="fa-solid fa-chevron-down"></i> </a> <style>.card:hover .card-img-top{transform:scale(1.1)}.card:hover{transform:translateY(-5px);box-shadow:0 10px 20px rgba(0,0,0,0.2)}.scroll-down-arrow{position:fixed;bottom:20px;left:20px;font-size:2rem;color:var(--color-text);background:var(--color-bg-secondary);border-radius:50%;padding:10px;z-index:1000;animation:float 1.5s ease-in-out infinite}@keyframes float{0%,100%{transform:translateY(0)}50%{transform:translateY(-10px)}}</style> <script>document.addEventListener("scroll",function(){const e=document.querySelector(".scroll-down-arrow"),o=document.documentElement.scrollHeight-window.innerHeight,n=window.scrollY;e.style.display=n>0&&n<o-50?"block":"none"}),document.querySelector(".scroll-down-arrow").addEventListener("click",function(e){e.preventDefault(),window.scrollBy({top:window.innerHeight,behavior:"smooth"})});</script> <div class="col"> <a href="https://link.springer.com/chapter/10.1007/978-3-031-31417-9_2" rel="external nofollow noopener" target="_blank"> <div class="card hoverable" style="min-height: 400px; display: flex; flex-direction: column; justify-content: space-between; transition: transform 0.3s ease, box-shadow 0.3s ease;"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/pearg-480.webp 480w,/assets/img/publication_preview/pearg-800.webp 800w,/assets/img/publication_preview/pearg-1400.webp 1400w," sizes="250px" type="image/webp"></source> <img src="/assets/img/publication_preview/pearg.png" class="card-img-top" width="100%" height="auto" alt="project thumbnail" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="card-body p-2" style="flex-grow: 1; overflow: hidden;"> <h2 class="card-title" style="font-size: 1.15rem; margin-bottom: 0.5rem; display: -webkit-box; -webkit-line-clamp: 3; -webkit-box-orient: vertical; overflow: hidden; text-overflow: ellipsis;">Pose Estimation for Autonomous Robotic Grasping</h2> <p class="card-text" style="font-size: 0.9rem; margin-bottom: 0.75rem; overflow: hidden; text-overflow: ellipsis; white-space: nowrap;"></p> <div class="row ml-1 mr-1 p-0 justify-content-between text-center" style="display: flex; justify-content: space-between;"> <div class="icon" data-toggle="tooltip" title="Report" style="flex: 1;"> <a href="/assets/pdf/pearg_final_report.pdf" class="text-decoration-none" style="color: inherit;"> <i class="fa-solid fa-file-pdf" style="font-size: 1.5rem;"></i> <div style="font-size: 0.75rem; color: inherit;">Report</div> </a> </div> <div class="icon" data-toggle="tooltip" title="Video" style="flex: 1;"> <a href="https://www.youtube.com/watch?v=fjW7IAH3shs" class="text-decoration-none" style="color: inherit;" rel="external nofollow noopener" target="_blank"> <i class="fa-solid fa-video" style="font-size: 1.5rem;"></i> <div style="font-size: 0.75rem; color: inherit;">Video</div> </a> </div> <div class="icon" data-toggle="tooltip" title="Slides" style="flex: 1;"> <a href="/assets/pdf/PPT_CVIP%202022.pdf" class="text-decoration-none" style="color: inherit;"> <i class="fa-solid fa-file-powerpoint" style="font-size: 1.5rem;"></i> <div style="font-size: 0.75rem; color: inherit;">Slides</div> </a> </div> <div class="icon" data-toggle="tooltip" title="Abstract" style="flex: 1;"> <a href="#abstract-Pose-Estimation-for-Autonomous-Robotic-Grasping" data-toggle="collapse" role="button" aria-expanded="false" aria-controls="abstract-Pose-Estimation-for-Autonomous-Robotic-Grasping" class="text-decoration-none" style="color: inherit;"> <i class="fa-solid fa-file-alt" style="font-size: 1.5rem;"></i> <div style="font-size: 0.75rem; color: inherit;">Abstract</div> </a> </div> </div> <div class="collapse mt-2" id="abstract-Pose-Estimation-for-Autonomous-Robotic-Grasping"> <div class="card card-body p-2" style="border: 1px dashed #ccc; font-size: 0.85rem;"> The ability of a robot to sense and “perceive" its surroundings to interact and influence various objects of interest by grasping them, using vision-based sensors is the main principle behind vision based Autonomous Robotic Grasping. To realise this task of autonomous object grasping, one of the critical sub-tasks is the 6D Pose Estimation of a known object of interest from sensory data in a given environment. The sensory data can include RGB images and data from depth sensors, but determining the object’s pose using only a single RGB image is cost-effective and highly desirable in many applications. In this work, we develop a series of convolutional neural network-based pose estimation models without post-refinement stages, designed to achieve high accuracy on relevant metrics for efficiently estimating the 6D pose of an object, using only a single RGB image. The designed models are incorporated into an end-to-end pose estimation pipeline based on Unity and ROS Noetic, where a UR3 Robotic Arm is deployed in a simulated pick-and-place task. The pose estimation performance of the different models is compared and analysed in both same-environment and cross-environment cases utilising synthetic RGB data collected from cluttered and simple simulation scenes constructed in Unity Environment. In addition, the developed models achieved high Average Distance (ADD) metric scores greater than 93% for most of the real-life objects tested in the LINEMOD dataset and can be integrated seamlessly with any robotic arm for estimating 6D pose from only RGB data, making our method effective, efficient and generic. </div> </div> </div> </div> </a> </div> <a href="#" class="scroll-down-arrow" style="display: none;"> <i class="fa-solid fa-chevron-down"></i> </a> <style>.card:hover .card-img-top{transform:scale(1.1)}.card:hover{transform:translateY(-5px);box-shadow:0 10px 20px rgba(0,0,0,0.2)}.scroll-down-arrow{position:fixed;bottom:20px;left:20px;font-size:2rem;color:var(--color-text);background:var(--color-bg-secondary);border-radius:50%;padding:10px;z-index:1000;animation:float 1.5s ease-in-out infinite}@keyframes float{0%,100%{transform:translateY(0)}50%{transform:translateY(-10px)}}</style> <script>document.addEventListener("scroll",function(){const e=document.querySelector(".scroll-down-arrow"),o=document.documentElement.scrollHeight-window.innerHeight,n=window.scrollY;e.style.display=n>0&&n<o-50?"block":"none"}),document.querySelector(".scroll-down-arrow").addEventListener("click",function(e){e.preventDefault(),window.scrollBy({top:window.innerHeight,behavior:"smooth"})});</script> <div class="col"> <a href="/projects/7_project/"> <div class="card hoverable" style="min-height: 400px; display: flex; flex-direction: column; justify-content: space-between; transition: transform 0.3s ease, box-shadow 0.3s ease;"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/mlsp-480.webp 480w,/assets/img/publication_preview/mlsp-800.webp 800w,/assets/img/publication_preview/mlsp-1400.webp 1400w," sizes="250px" type="image/webp"></source> <img src="/assets/img/publication_preview/mlsp.png" class="card-img-top" width="100%" height="auto" alt="project thumbnail" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="card-body p-2" style="flex-grow: 1; overflow: hidden;"> <h2 class="card-title" style="font-size: 1.15rem; margin-bottom: 0.5rem; display: -webkit-box; -webkit-line-clamp: 3; -webkit-box-orient: vertical; overflow: hidden; text-overflow: ellipsis;">Scene Text Recognition</h2> <p class="card-text" style="font-size: 0.9rem; margin-bottom: 0.75rem; overflow: hidden; text-overflow: ellipsis; white-space: nowrap;"></p> <div class="row ml-1 mr-1 p-0 justify-content-between text-center" style="display: flex; justify-content: space-between;"> <div class="icon" data-toggle="tooltip" title="Report" style="flex: 1;"> <a href="/assets/pdf/MLSP_Project_Report.pdf" class="text-decoration-none" style="color: inherit;"> <i class="fa-solid fa-file-pdf" style="font-size: 1.5rem;"></i> <div style="font-size: 0.75rem; color: inherit;">Report</div> </a> </div> <div class="icon" data-toggle="tooltip" title="Slides" style="flex: 1;"> <a href="/assets/pdf/mlsp_ppt.pdf" class="text-decoration-none" style="color: inherit;"> <i class="fa-solid fa-file-powerpoint" style="font-size: 1.5rem;"></i> <div style="font-size: 0.75rem; color: inherit;">Slides</div> </a> </div> <div class="icon" data-toggle="tooltip" title="Abstract" style="flex: 1;"> <a href="#abstract-Scene-Text-Recognition" data-toggle="collapse" role="button" aria-expanded="false" aria-controls="abstract-Scene-Text-Recognition" class="text-decoration-none" style="color: inherit;"> <i class="fa-solid fa-file-alt" style="font-size: 1.5rem;"></i> <div style="font-size: 0.75rem; color: inherit;">Abstract</div> </a> </div> </div> <div class="collapse mt-2" id="abstract-Scene-Text-Recognition"> <div class="card card-body p-2" style="border: 1px dashed #ccc; font-size: 0.85rem;"> Text is one of the most effective forms of communication among human beings. Recognizing text automatically &amp; efficiently in everyday scenes is an invaluable tool in many applications. In this project, we delve into the fascinating domain of Scene Text Recognition (STR) utilizing advanced deep learning methodologies. This project addresses the crucial task of automatic text recognition in natural scenes, a challenge due to the intertwined visual and semantic information and the variability in text appearance caused by environmental factors. We explore and experiment with various architectures, including Convolutional Neural Networks (CNNs) for visual feature extraction and Recurrent Neural Networks (RNNs) for semantic understanding, focusing on both regular and irregular text recognition. Notably, our work incorporates Spatial Transformation Networks (STNs) to rectify distorted text, enhancing the accuracy of text recognition. Through rigorous experimentation and analysis on diverse datasets, we provide insights into the models' performance, contributing valuable knowledge for applications in document analysis, autonomous vehicles, and augmented reality. Our findings indicate the potential for significant advancements in STR, paving the way for future research and practical implementations. </div> </div> </div> </div> </a> </div> <a href="#" class="scroll-down-arrow" style="display: none;"> <i class="fa-solid fa-chevron-down"></i> </a> <style>.card:hover .card-img-top{transform:scale(1.1)}.card:hover{transform:translateY(-5px);box-shadow:0 10px 20px rgba(0,0,0,0.2)}.scroll-down-arrow{position:fixed;bottom:20px;left:20px;font-size:2rem;color:var(--color-text);background:var(--color-bg-secondary);border-radius:50%;padding:10px;z-index:1000;animation:float 1.5s ease-in-out infinite}@keyframes float{0%,100%{transform:translateY(0)}50%{transform:translateY(-10px)}}</style> <script>document.addEventListener("scroll",function(){const e=document.querySelector(".scroll-down-arrow"),o=document.documentElement.scrollHeight-window.innerHeight,n=window.scrollY;e.style.display=n>0&&n<o-50?"block":"none"}),document.querySelector(".scroll-down-arrow").addEventListener("click",function(e){e.preventDefault(),window.scrollBy({top:window.innerHeight,behavior:"smooth"})});</script> <div class="col"> <a href="/projects/7_project_2/"> <div class="card hoverable" style="min-height: 400px; display: flex; flex-direction: column; justify-content: space-between; transition: transform 0.3s ease, box-shadow 0.3s ease;"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/proc-480.webp 480w,/assets/img/publication_preview/proc-800.webp 800w,/assets/img/publication_preview/proc-1400.webp 1400w," sizes="250px" type="image/webp"></source> <img src="/assets/img/publication_preview/proc.png" class="card-img-top" width="100%" height="auto" alt="project thumbnail" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="card-body p-2" style="flex-grow: 1; overflow: hidden;"> <h2 class="card-title" style="font-size: 1.15rem; margin-bottom: 0.5rem; display: -webkit-box; -webkit-line-clamp: 3; -webkit-box-orient: vertical; overflow: hidden; text-overflow: ellipsis;">Swadeshi Microprocessor Challenge</h2> <p class="card-text" style="font-size: 0.9rem; margin-bottom: 0.75rem; overflow: hidden; text-overflow: ellipsis; white-space: nowrap;"></p> <div class="row ml-1 mr-1 p-0 justify-content-between text-center" style="display: flex; justify-content: space-between;"> <div class="icon" data-toggle="tooltip" title="Code Repository" style="flex: 1;"> <a href="https://github.com/dsriaditya999/ProjIkshana" class="text-decoration-none" style="color: inherit;" rel="external nofollow noopener" target="_blank"> <i class="fa-brands fa-github" style="font-size: 1.5rem;"></i> <div style="font-size: 0.75rem; color: inherit;">Code</div> </a> </div> <div class="icon" data-toggle="tooltip" title="Abstract" style="flex: 1;"> <a href="#abstract-Swadeshi-Microprocessor-Challenge" data-toggle="collapse" role="button" aria-expanded="false" aria-controls="abstract-Swadeshi-Microprocessor-Challenge" class="text-decoration-none" style="color: inherit;"> <i class="fa-solid fa-file-alt" style="font-size: 1.5rem;"></i> <div style="font-size: 0.75rem; color: inherit;">Abstract</div> </a> </div> </div> <div class="collapse mt-2" id="abstract-Swadeshi-Microprocessor-Challenge"> <div class="card card-body p-2" style="border: 1px dashed #ccc; font-size: 0.85rem;"> Technological advancements in Signal Processing and millimeter-wave (mm-wave) semiconductor technology have significantly impacted the automobile industry, particularly in enhancing Autonomous Vehicles and Advanced Driving Assistance Systems (ADAS). Automotive radar, particularly Frequency Modulated Continuous Wave (FMCW) radars, has become a popular choice for robust and cost-effective performance in challenging environmental conditions. The proposed Ikshana FMCW Radar Module, utilizing the Vajra (C64-A100, Shakti C-class) SoC from IIT Madras, aims to provide a low-cost, indigenous solution for applications such as autonomous vehicles and night-vision goggles. Implemented on a Xilinx Arty A7 FPGA with planned soft-core extensions, this module represents an innovative approach to leveraging indigenous microprocessors, as highlighted in the Swadeshi Microprocessor Challenge by the Ministry of Electronics and Information Technology, Government of India. </div> </div> </div> </div> </a> </div> <a href="#" class="scroll-down-arrow" style="display: none;"> <i class="fa-solid fa-chevron-down"></i> </a> <style>.card:hover .card-img-top{transform:scale(1.1)}.card:hover{transform:translateY(-5px);box-shadow:0 10px 20px rgba(0,0,0,0.2)}.scroll-down-arrow{position:fixed;bottom:20px;left:20px;font-size:2rem;color:var(--color-text);background:var(--color-bg-secondary);border-radius:50%;padding:10px;z-index:1000;animation:float 1.5s ease-in-out infinite}@keyframes float{0%,100%{transform:translateY(0)}50%{transform:translateY(-10px)}}</style> <script>document.addEventListener("scroll",function(){const e=document.querySelector(".scroll-down-arrow"),o=document.documentElement.scrollHeight-window.innerHeight,n=window.scrollY;e.style.display=n>0&&n<o-50?"block":"none"}),document.querySelector(".scroll-down-arrow").addEventListener("click",function(e){e.preventDefault(),window.scrollBy({top:window.innerHeight,behavior:"smooth"})});</script> <div class="col"> <a href="/projects/7_project_1/"> <div class="card hoverable" style="min-height: 400px; display: flex; flex-direction: column; justify-content: space-between; transition: transform 0.3s ease, box-shadow 0.3s ease;"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/asr-480.webp 480w,/assets/img/publication_preview/asr-800.webp 800w,/assets/img/publication_preview/asr-1400.webp 1400w," sizes="250px" type="image/webp"></source> <img src="/assets/img/publication_preview/asr.png" class="card-img-top" width="100%" height="auto" alt="project thumbnail" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="card-body p-2" style="flex-grow: 1; overflow: hidden;"> <h2 class="card-title" style="font-size: 1.15rem; margin-bottom: 0.5rem; display: -webkit-box; -webkit-line-clamp: 3; -webkit-box-orient: vertical; overflow: hidden; text-overflow: ellipsis;">Automatic Speaker Recognition System</h2> <p class="card-text" style="font-size: 0.9rem; margin-bottom: 0.75rem; overflow: hidden; text-overflow: ellipsis; white-space: nowrap;"></p> <div class="row ml-1 mr-1 p-0 justify-content-between text-center" style="display: flex; justify-content: space-between;"> <div class="icon" data-toggle="tooltip" title="Code Repository" style="flex: 1;"> <a href="https://github.com/dsriaditya999/RecogSpeak/tree/main" class="text-decoration-none" style="color: inherit;" rel="external nofollow noopener" target="_blank"> <i class="fa-brands fa-github" style="font-size: 1.5rem;"></i> <div style="font-size: 0.75rem; color: inherit;">Code</div> </a> </div> <div class="icon" data-toggle="tooltip" title="Slides" style="flex: 1;"> <a href="/assets/pdf/ASR_Presentation.pdf" class="text-decoration-none" style="color: inherit;"> <i class="fa-solid fa-file-powerpoint" style="font-size: 1.5rem;"></i> <div style="font-size: 0.75rem; color: inherit;">Slides</div> </a> </div> <div class="icon" data-toggle="tooltip" title="Abstract" style="flex: 1;"> <a href="#abstract-Automatic-Speaker-Recognition-System" data-toggle="collapse" role="button" aria-expanded="false" aria-controls="abstract-Automatic-Speaker-Recognition-System" class="text-decoration-none" style="color: inherit;"> <i class="fa-solid fa-file-alt" style="font-size: 1.5rem;"></i> <div style="font-size: 0.75rem; color: inherit;">Abstract</div> </a> </div> </div> <div class="collapse mt-2" id="abstract-Automatic-Speaker-Recognition-System"> <div class="card card-body p-2" style="border: 1px dashed #ccc; font-size: 0.85rem;"> The "Automatic Speaker Recognition" (ASR) project focuses on developing a robust system capable of recognizing speakers based on unique characteristics in their speech. This system utilizes key techniques such as Mel Frequency Cepstral Coefficients (MFCCs) for feature extraction and Vector Quantization (VQ) using the KMeans clustering algorithm for pattern recognition. During the training phase, speech samples from various speakers are processed to build individual speaker-specific codebooks. In the testing phase, unknown speech samples are matched against these codebooks to identify the speaker. The project includes validation using real-life speech data from multiple speakers, ensuring the system's accuracy and reliability under varied conditions. This project demonstrates practical applications in areas such as telephone banking, remote computer access security, and identity verification, highlighting the effectiveness of ASR systems in enhancing security and user authentication processes. </div> </div> </div> </div> </a> </div> <a href="#" class="scroll-down-arrow" style="display: none;"> <i class="fa-solid fa-chevron-down"></i> </a> <style>.card:hover .card-img-top{transform:scale(1.1)}.card:hover{transform:translateY(-5px);box-shadow:0 10px 20px rgba(0,0,0,0.2)}.scroll-down-arrow{position:fixed;bottom:20px;left:20px;font-size:2rem;color:var(--color-text);background:var(--color-bg-secondary);border-radius:50%;padding:10px;z-index:1000;animation:float 1.5s ease-in-out infinite}@keyframes float{0%,100%{transform:translateY(0)}50%{transform:translateY(-10px)}}</style> <script>document.addEventListener("scroll",function(){const e=document.querySelector(".scroll-down-arrow"),o=document.documentElement.scrollHeight-window.innerHeight,n=window.scrollY;e.style.display=n>0&&n<o-50?"block":"none"}),document.querySelector(".scroll-down-arrow").addEventListener("click",function(e){e.preventDefault(),window.scrollBy({top:window.innerHeight,behavior:"smooth"})});</script> <div class="col"> <a href="/projects/8_project/"> <div class="card hoverable" style="min-height: 400px; display: flex; flex-direction: column; justify-content: space-between; transition: transform 0.3s ease, box-shadow 0.3s ease;"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/anomaly-480.webp 480w,/assets/img/publication_preview/anomaly-800.webp 800w,/assets/img/publication_preview/anomaly-1400.webp 1400w," sizes="250px" type="image/webp"></source> <img src="/assets/img/publication_preview/anomaly.png" class="card-img-top" width="100%" height="auto" alt="project thumbnail" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="card-body p-2" style="flex-grow: 1; overflow: hidden;"> <h2 class="card-title" style="font-size: 1.15rem; margin-bottom: 0.5rem; display: -webkit-box; -webkit-line-clamp: 3; -webkit-box-orient: vertical; overflow: hidden; text-overflow: ellipsis;">Anomaly Detection in Satellite Telemetry</h2> <p class="card-text" style="font-size: 0.9rem; margin-bottom: 0.75rem; overflow: hidden; text-overflow: ellipsis; white-space: nowrap;"></p> <div class="row ml-1 mr-1 p-0 justify-content-between text-center" style="display: flex; justify-content: space-between;"> <div class="icon" data-toggle="tooltip" title="Abstract" style="flex: 1;"> <a href="#abstract-Anomaly-Detection-in-Satellite-Telemetry" data-toggle="collapse" role="button" aria-expanded="false" aria-controls="abstract-Anomaly-Detection-in-Satellite-Telemetry" class="text-decoration-none" style="color: inherit;"> <i class="fa-solid fa-file-alt" style="font-size: 1.5rem;"></i> <div style="font-size: 0.75rem; color: inherit;">Abstract</div> </a> </div> </div> <div class="collapse mt-2" id="abstract-Anomaly-Detection-in-Satellite-Telemetry"> <div class="card card-body p-2" style="border: 1px dashed #ccc; font-size: 0.85rem;"> The project involved addressing various research problems within the "Integrated System Health Management for Power Systems (ISHM)" initiative. The primary focus was on developing anomaly detection techniques under Phase-II - Fault Detection. An Anomaly Detection System was developed, incorporating an LSTM-based Nominal Behaviour Modelling block and a Non-parametric Dynamic Error Thresholding block. This system was designed to detect anomalies in satellite telemetry data, thereby enhancing the reliability and safety of space subsystems through advanced fault detection methods. </div> </div> </div> </div> </a> </div> <a href="#" class="scroll-down-arrow" style="display: none;"> <i class="fa-solid fa-chevron-down"></i> </a> <style>.card:hover .card-img-top{transform:scale(1.1)}.card:hover{transform:translateY(-5px);box-shadow:0 10px 20px rgba(0,0,0,0.2)}.scroll-down-arrow{position:fixed;bottom:20px;left:20px;font-size:2rem;color:var(--color-text);background:var(--color-bg-secondary);border-radius:50%;padding:10px;z-index:1000;animation:float 1.5s ease-in-out infinite}@keyframes float{0%,100%{transform:translateY(0)}50%{transform:translateY(-10px)}}</style> <script>document.addEventListener("scroll",function(){const e=document.querySelector(".scroll-down-arrow"),o=document.documentElement.scrollHeight-window.innerHeight,n=window.scrollY;e.style.display=n>0&&n<o-50?"block":"none"}),document.querySelector(".scroll-down-arrow").addEventListener("click",function(e){e.preventDefault(),window.scrollBy({top:window.innerHeight,behavior:"smooth"})});</script> <div class="col"> <a href="https://link.springer.com/article/10.1007/s13534-021-00184-x" rel="external nofollow noopener" target="_blank"> <div class="card hoverable" style="min-height: 400px; display: flex; flex-direction: column; justify-content: space-between; transition: transform 0.3s ease, box-shadow 0.3s ease;"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/random_ecg-480.webp 480w,/assets/img/publication_preview/random_ecg-800.webp 800w,/assets/img/publication_preview/random_ecg-1400.webp 1400w," sizes="250px" type="image/webp"></source> <img src="/assets/img/publication_preview/random_ecg.png" class="card-img-top" width="100%" height="auto" alt="project thumbnail" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="card-body p-2" style="flex-grow: 1; overflow: hidden;"> <h2 class="card-title" style="font-size: 1.15rem; margin-bottom: 0.5rem; display: -webkit-box; -webkit-line-clamp: 3; -webkit-box-orient: vertical; overflow: hidden; text-overflow: ellipsis;">ECG Beat Classification</h2> <p class="card-text" style="font-size: 0.9rem; margin-bottom: 0.75rem; overflow: hidden; text-overflow: ellipsis; white-space: nowrap;"></p> <div class="row ml-1 mr-1 p-0 justify-content-between text-center" style="display: flex; justify-content: space-between;"> <div class="icon" data-toggle="tooltip" title="Code Repository" style="flex: 1;"> <a href="https://www.sriadityadeevi.com/ecgheartnetec.github.io/" class="text-decoration-none" style="color: inherit;" rel="external nofollow noopener" target="_blank"> <i class="fa-brands fa-github" style="font-size: 1.5rem;"></i> <div style="font-size: 0.75rem; color: inherit;">Code</div> </a> </div> <div class="icon" data-toggle="tooltip" title="Abstract" style="flex: 1;"> <a href="#abstract-ECG-Beat-Classification" data-toggle="collapse" role="button" aria-expanded="false" aria-controls="abstract-ECG-Beat-Classification" class="text-decoration-none" style="color: inherit;"> <i class="fa-solid fa-file-alt" style="font-size: 1.5rem;"></i> <div style="font-size: 0.75rem; color: inherit;">Abstract</div> </a> </div> </div> <div class="collapse mt-2" id="abstract-ECG-Beat-Classification"> <div class="card card-body p-2" style="border: 1px dashed #ccc; font-size: 0.85rem;"> One of the most crucial and informative tools available at the disposal of a Cardiologist for examining the condition of a patient’s cardiovascular system is the electrocardiogram (ECG/EKG). A major reason behind the need for accurate reconstruction of ECG comes from the fact that the shape of ECG tracing is very crucial for determining the health condition of an individual. Whether the patient is prone to or diagnosed with cardiovascular diseases (CVDs), this information can be gathered through examination of ECG signal. Among various other methods, one of the most helpful methods in identifying cardiac abnormalities is a beat-wise categorization of a patient’s ECG record. In this work, a highly efficient deep representation learning approach for ECG beat classification is proposed, which can significantly reduce the burden and time spent by a Cardiologist for ECG Analysis. This work consists of two sub-systems - denoising block and beat classification block. The initial block is a denoising block that acquires the ECG signal from the patient and denoises that. The next stage is the beat classification part. This processes the input ECG signal for finding out the different classes of beats in the ECG through an efficient algorithm. In both stages, deep learning-based methods have been employed for the purpose. Our proposed approach has been tested on PhysioNet’s MIT-BIH Arrhythmia Database, for beat-wise classification into ten important types of heartbeats. As per the results obtained, the proposed approach is capable of making meaningful predictions and gives superior results on relevant metrics. </div> </div> </div> </div> </a> </div> <a href="#" class="scroll-down-arrow" style="display: none;"> <i class="fa-solid fa-chevron-down"></i> </a> <style>.card:hover .card-img-top{transform:scale(1.1)}.card:hover{transform:translateY(-5px);box-shadow:0 10px 20px rgba(0,0,0,0.2)}.scroll-down-arrow{position:fixed;bottom:20px;left:20px;font-size:2rem;color:var(--color-text);background:var(--color-bg-secondary);border-radius:50%;padding:10px;z-index:1000;animation:float 1.5s ease-in-out infinite}@keyframes float{0%,100%{transform:translateY(0)}50%{transform:translateY(-10px)}}</style> <script>document.addEventListener("scroll",function(){const e=document.querySelector(".scroll-down-arrow"),o=document.documentElement.scrollHeight-window.innerHeight,n=window.scrollY;e.style.display=n>0&&n<o-50?"block":"none"}),document.querySelector(".scroll-down-arrow").addEventListener("click",function(e){e.preventDefault(),window.scrollBy({top:window.innerHeight,behavior:"smooth"})});</script> <div class="col"> <a href="/projects/10_project/"> <div class="card hoverable" style="min-height: 400px; display: flex; flex-direction: column; justify-content: space-between; transition: transform 0.3s ease, box-shadow 0.3s ease;"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/iot_bulb-480.webp 480w,/assets/img/publication_preview/iot_bulb-800.webp 800w,/assets/img/publication_preview/iot_bulb-1400.webp 1400w," sizes="250px" type="image/webp"></source> <img src="/assets/img/publication_preview/iot_bulb.png" class="card-img-top" width="100%" height="auto" alt="project thumbnail" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="card-body p-2" style="flex-grow: 1; overflow: hidden;"> <h2 class="card-title" style="font-size: 1.15rem; margin-bottom: 0.5rem; display: -webkit-box; -webkit-line-clamp: 3; -webkit-box-orient: vertical; overflow: hidden; text-overflow: ellipsis;">IoT controlled Smart Home</h2> <p class="card-text" style="font-size: 0.9rem; margin-bottom: 0.75rem; overflow: hidden; text-overflow: ellipsis; white-space: nowrap;"></p> <div class="row ml-1 mr-1 p-0 justify-content-between text-center" style="display: flex; justify-content: space-between;"> <div class="icon" data-toggle="tooltip" title="Code Repository" style="flex: 1;"> <a href="https://github.com/dsriaditya999/IoT-Bulb" class="text-decoration-none" style="color: inherit;" rel="external nofollow noopener" target="_blank"> <i class="fa-brands fa-github" style="font-size: 1.5rem;"></i> <div style="font-size: 0.75rem; color: inherit;">Code</div> </a> </div> <div class="icon" data-toggle="tooltip" title="Report" style="flex: 1;"> <a href="/assets/pdf/iot_bulb.pdf" class="text-decoration-none" style="color: inherit;"> <i class="fa-solid fa-file-pdf" style="font-size: 1.5rem;"></i> <div style="font-size: 0.75rem; color: inherit;">Report</div> </a> </div> <div class="icon" data-toggle="tooltip" title="Video" style="flex: 1;"> <a href="/assets/video/iot_bulb.mp4" class="text-decoration-none" style="color: inherit;"> <i class="fa-solid fa-video" style="font-size: 1.5rem;"></i> <div style="font-size: 0.75rem; color: inherit;">Video</div> </a> </div> <div class="icon" data-toggle="tooltip" title="Abstract" style="flex: 1;"> <a href="#abstract-IoT-controlled-Smart-Home" data-toggle="collapse" role="button" aria-expanded="false" aria-controls="abstract-IoT-controlled-Smart-Home" class="text-decoration-none" style="color: inherit;"> <i class="fa-solid fa-file-alt" style="font-size: 1.5rem;"></i> <div style="font-size: 0.75rem; color: inherit;">Abstract</div> </a> </div> </div> <div class="collapse mt-2" id="abstract-IoT-controlled-Smart-Home"> <div class="card card-body p-2" style="border: 1px dashed #ccc; font-size: 0.85rem;"> This project exemplifies the transformative potential of the Internet of Things (IoT) by enabling voice-controlled automation of household lighting through Google Assistant. It utilizes an Arduino UNO, ESP8266 WiFi module, and a dual-channel relay to create an auxiliary circuit that can control a standard light bulb with voice commands. By integrating the system with ThingSpeak for data management and IFTTT for seamless interaction between Google Assistant and the IoT devices, users can effortlessly turn the light on or off by simply saying "OK Google, Lights ON" or "OK Google, Lights OFF." The project demonstrates the practical application of IoT in enhancing home automation, emphasizing ease of use, convenience, and the power of modern technology to simplify daily tasks. This innovative solution not only highlights the capabilities of IoT but also provides a glimpse into the future of smart homes, where everyday actions can be managed through intuitive voice commands. </div> </div> </div> </div> </a> </div> <a href="#" class="scroll-down-arrow" style="display: none;"> <i class="fa-solid fa-chevron-down"></i> </a> <style>.card:hover .card-img-top{transform:scale(1.1)}.card:hover{transform:translateY(-5px);box-shadow:0 10px 20px rgba(0,0,0,0.2)}.scroll-down-arrow{position:fixed;bottom:20px;left:20px;font-size:2rem;color:var(--color-text);background:var(--color-bg-secondary);border-radius:50%;padding:10px;z-index:1000;animation:float 1.5s ease-in-out infinite}@keyframes float{0%,100%{transform:translateY(0)}50%{transform:translateY(-10px)}}</style> <script>document.addEventListener("scroll",function(){const e=document.querySelector(".scroll-down-arrow"),o=document.documentElement.scrollHeight-window.innerHeight,n=window.scrollY;e.style.display=n>0&&n<o-50?"block":"none"}),document.querySelector(".scroll-down-arrow").addEventListener("click",function(e){e.preventDefault(),window.scrollBy({top:window.innerHeight,behavior:"smooth"})});</script> <div class="col"> <a href="/projects/11_project/"> <div class="card hoverable" style="min-height: 400px; display: flex; flex-direction: column; justify-content: space-between; transition: transform 0.3s ease, box-shadow 0.3s ease;"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/vc_bot-480.webp 480w,/assets/img/publication_preview/vc_bot-800.webp 800w,/assets/img/publication_preview/vc_bot-1400.webp 1400w," sizes="250px" type="image/webp"></source> <img src="/assets/img/publication_preview/vc_bot.png" class="card-img-top" width="100%" height="auto" alt="project thumbnail" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="card-body p-2" style="flex-grow: 1; overflow: hidden;"> <h2 class="card-title" style="font-size: 1.15rem; margin-bottom: 0.5rem; display: -webkit-box; -webkit-line-clamp: 3; -webkit-box-orient: vertical; overflow: hidden; text-overflow: ellipsis;">Voice Controlled Robot</h2> <p class="card-text" style="font-size: 0.9rem; margin-bottom: 0.75rem; overflow: hidden; text-overflow: ellipsis; white-space: nowrap;"></p> <div class="row ml-1 mr-1 p-0 justify-content-between text-center" style="display: flex; justify-content: space-between;"> <div class="icon" data-toggle="tooltip" title="Code Repository" style="flex: 1;"> <a href="https://github.com/dsriaditya999/Voice-Controlled-Bot" class="text-decoration-none" style="color: inherit;" rel="external nofollow noopener" target="_blank"> <i class="fa-brands fa-github" style="font-size: 1.5rem;"></i> <div style="font-size: 0.75rem; color: inherit;">Code</div> </a> </div> <div class="icon" data-toggle="tooltip" title="Report" style="flex: 1;"> <a href="/assets/pdf/vc_bot.pdf" class="text-decoration-none" style="color: inherit;"> <i class="fa-solid fa-file-pdf" style="font-size: 1.5rem;"></i> <div style="font-size: 0.75rem; color: inherit;">Report</div> </a> </div> <div class="icon" data-toggle="tooltip" title="Video" style="flex: 1;"> <a href="/assets/video/vc_bot.mp4" class="text-decoration-none" style="color: inherit;"> <i class="fa-solid fa-video" style="font-size: 1.5rem;"></i> <div style="font-size: 0.75rem; color: inherit;">Video</div> </a> </div> <div class="icon" data-toggle="tooltip" title="Abstract" style="flex: 1;"> <a href="#abstract-Voice-Controlled-Robot" data-toggle="collapse" role="button" aria-expanded="false" aria-controls="abstract-Voice-Controlled-Robot" class="text-decoration-none" style="color: inherit;"> <i class="fa-solid fa-file-alt" style="font-size: 1.5rem;"></i> <div style="font-size: 0.75rem; color: inherit;">Abstract</div> </a> </div> </div> <div class="collapse mt-2" id="abstract-Voice-Controlled-Robot"> <div class="card card-body p-2" style="border: 1px dashed #ccc; font-size: 0.85rem;"> This project leverages voice recognition technology to enable precise and intuitive control over a robot's movements. Developed using an Arduino UNO, HC05 Bluetooth module, and L298N Motor Driver, the robot receives voice commands via a mobile phone application, translating spoken instructions into actions such as moving forward, backward, left, or right. The robot's design includes essential components like wheels, a chassis, DC motors, and an LM393 Speed Sensor, all integrated to ensure accurate movement and stability. The voice commands are processed and transmitted from the smartphone to the robot through the Bluetooth module, enabling seamless communication and control. This project showcases the potential of combining natural language processing with robotics, providing a user-friendly interface for operating robotic systems and demonstrating the practical applications of voice-controlled technology in enhancing human-robot interaction. The project's implementation not only highlights technical proficiency in robotics and programming but also emphasizes the innovative use of voice control to simplify and enhance the user experience. </div> </div> </div> </div> </a> </div> <a href="#" class="scroll-down-arrow" style="display: none;"> <i class="fa-solid fa-chevron-down"></i> </a> <style>.card:hover .card-img-top{transform:scale(1.1)}.card:hover{transform:translateY(-5px);box-shadow:0 10px 20px rgba(0,0,0,0.2)}.scroll-down-arrow{position:fixed;bottom:20px;left:20px;font-size:2rem;color:var(--color-text);background:var(--color-bg-secondary);border-radius:50%;padding:10px;z-index:1000;animation:float 1.5s ease-in-out infinite}@keyframes float{0%,100%{transform:translateY(0)}50%{transform:translateY(-10px)}}</style> <script>document.addEventListener("scroll",function(){const e=document.querySelector(".scroll-down-arrow"),o=document.documentElement.scrollHeight-window.innerHeight,n=window.scrollY;e.style.display=n>0&&n<o-50?"block":"none"}),document.querySelector(".scroll-down-arrow").addEventListener("click",function(e){e.preventDefault(),window.scrollBy({top:window.innerHeight,behavior:"smooth"})});</script> <div class="col"> <a href="/projects/12_project/"> <div class="card hoverable" style="min-height: 400px; display: flex; flex-direction: column; justify-content: space-between; transition: transform 0.3s ease, box-shadow 0.3s ease;"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/fri-480.webp 480w,/assets/img/publication_preview/fri-800.webp 800w,/assets/img/publication_preview/fri-1400.webp 1400w," sizes="250px" type="image/webp"></source> <img src="/assets/img/publication_preview/fri.png" class="card-img-top" width="100%" height="auto" alt="project thumbnail" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="card-body p-2" style="flex-grow: 1; overflow: hidden;"> <h2 class="card-title" style="font-size: 1.15rem; margin-bottom: 0.5rem; display: -webkit-box; -webkit-line-clamp: 3; -webkit-box-orient: vertical; overflow: hidden; text-overflow: ellipsis;">Fiscal Responsibility Index</h2> <p class="card-text" style="font-size: 0.9rem; margin-bottom: 0.75rem; overflow: hidden; text-overflow: ellipsis; white-space: nowrap;"></p> <div class="row ml-1 mr-1 p-0 justify-content-between text-center" style="display: flex; justify-content: space-between;"> <div class="icon" data-toggle="tooltip" title="Report" style="flex: 1;"> <a href="/assets/pdf/fri_report.pdf" class="text-decoration-none" style="color: inherit;"> <i class="fa-solid fa-file-pdf" style="font-size: 1.5rem;"></i> <div style="font-size: 0.75rem; color: inherit;">Report</div> </a> </div> <div class="icon" data-toggle="tooltip" title="Abstract" style="flex: 1;"> <a href="#abstract-Fiscal-Responsibility-Index" data-toggle="collapse" role="button" aria-expanded="false" aria-controls="abstract-Fiscal-Responsibility-Index" class="text-decoration-none" style="color: inherit;"> <i class="fa-solid fa-file-alt" style="font-size: 1.5rem;"></i> <div style="font-size: 0.75rem; color: inherit;">Abstract</div> </a> </div> </div> <div class="collapse mt-2" id="abstract-Fiscal-Responsibility-Index"> <div class="card card-body p-2" style="border: 1px dashed #ccc; font-size: 0.85rem;"> The Fiscal Responsibility Index (FRI) project is a comprehensive analysis aimed at quantifying the fiscal responsibility of a government by creating an index that evaluates how well a government manages its monetary resources. Developed as part of a B.Tech Economics project, the FRI considers various parameters such as fiscal deficit, revenue deficit, primary deficit, and their impact on the overall economy. The project involves extensive data collection from sources like the RBI and World Bank, and uses MATLAB for modeling these parameters to derive a mathematical formula that represents fiscal responsibility. The index helps in assessing the government’s efficiency in balancing developmental expenditures with debt management, ensuring sustainable growth. By analyzing historical data and incorporating factors like GDP growth rate and total outstanding liabilities, the FRI provides a nuanced report card of a government's fiscal discipline, offering valuable insights for policy-making and economic planning. </div> </div> </div> </div> </a> </div> <a href="#" class="scroll-down-arrow" style="display: none;"> <i class="fa-solid fa-chevron-down"></i> </a> <style>.card:hover .card-img-top{transform:scale(1.1)}.card:hover{transform:translateY(-5px);box-shadow:0 10px 20px rgba(0,0,0,0.2)}.scroll-down-arrow{position:fixed;bottom:20px;left:20px;font-size:2rem;color:var(--color-text);background:var(--color-bg-secondary);border-radius:50%;padding:10px;z-index:1000;animation:float 1.5s ease-in-out infinite}@keyframes float{0%,100%{transform:translateY(0)}50%{transform:translateY(-10px)}}</style> <script>document.addEventListener("scroll",function(){const e=document.querySelector(".scroll-down-arrow"),o=document.documentElement.scrollHeight-window.innerHeight,n=window.scrollY;e.style.display=n>0&&n<o-50?"block":"none"}),document.querySelector(".scroll-down-arrow").addEventListener("click",function(e){e.preventDefault(),window.scrollBy({top:window.innerHeight,behavior:"smooth"})});</script> <div class="col"> <a href="/projects/13_project/"> <div class="card hoverable" style="min-height: 400px; display: flex; flex-direction: column; justify-content: space-between; transition: transform 0.3s ease, box-shadow 0.3s ease;"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/fire_alarm-480.webp 480w,/assets/img/publication_preview/fire_alarm-800.webp 800w,/assets/img/publication_preview/fire_alarm-1400.webp 1400w," sizes="250px" type="image/webp"></source> <img src="/assets/img/publication_preview/fire_alarm.png" class="card-img-top" width="100%" height="auto" alt="project thumbnail" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="card-body p-2" style="flex-grow: 1; overflow: hidden;"> <h2 class="card-title" style="font-size: 1.15rem; margin-bottom: 0.5rem; display: -webkit-box; -webkit-line-clamp: 3; -webkit-box-orient: vertical; overflow: hidden; text-overflow: ellipsis;">Fire Alarm</h2> <p class="card-text" style="font-size: 0.9rem; margin-bottom: 0.75rem; overflow: hidden; text-overflow: ellipsis; white-space: nowrap;"></p> <div class="row ml-1 mr-1 p-0 justify-content-between text-center" style="display: flex; justify-content: space-between;"> <div class="icon" data-toggle="tooltip" title="Report" style="flex: 1;"> <a href="/assets/pdf/fire_alarm.pdf" class="text-decoration-none" style="color: inherit;"> <i class="fa-solid fa-file-pdf" style="font-size: 1.5rem;"></i> <div style="font-size: 0.75rem; color: inherit;">Report</div> </a> </div> <div class="icon" data-toggle="tooltip" title="Video" style="flex: 1;"> <a href="/assets/video/fire_alarm.mp4" class="text-decoration-none" style="color: inherit;"> <i class="fa-solid fa-video" style="font-size: 1.5rem;"></i> <div style="font-size: 0.75rem; color: inherit;">Video</div> </a> </div> <div class="icon" data-toggle="tooltip" title="Abstract" style="flex: 1;"> <a href="#abstract-Fire-Alarm" data-toggle="collapse" role="button" aria-expanded="false" aria-controls="abstract-Fire-Alarm" class="text-decoration-none" style="color: inherit;"> <i class="fa-solid fa-file-alt" style="font-size: 1.5rem;"></i> <div style="font-size: 0.75rem; color: inherit;">Abstract</div> </a> </div> </div> <div class="collapse mt-2" id="abstract-Fire-Alarm"> <div class="card card-body p-2" style="border: 1px dashed #ccc; font-size: 0.85rem;"> The Fire Alarm with Intensity Meter project is an innovative analog electronics application designed to detect and indicate the presence and intensity of fire using temperature changes. The system employs an NTC (Negative Temperature Coefficient) thermistor to sense temperature variations, where its resistance decreases as temperature increases. When the temperature exceeds 50°C, the output from an IC741 comparator triggers a 555 Timer configured as an astable multivibrator, activating an alarm. Simultaneously, a series of LED indicators, driven by additional IC741 comparators, display the fire's intensity by lighting up progressively with each 10°C increase. The system is powered by multiple DC supplies and includes components like resistors, capacitors, and a speaker for alarm output. This project effectively demonstrates the integration of temperature sensing, signal processing, and user notification in a practical fire alarm system, providing a comprehensive solution for early fire detection and intensity measurement. </div> </div> </div> </div> </a> </div> <a href="#" class="scroll-down-arrow" style="display: none;"> <i class="fa-solid fa-chevron-down"></i> </a> <style>.card:hover .card-img-top{transform:scale(1.1)}.card:hover{transform:translateY(-5px);box-shadow:0 10px 20px rgba(0,0,0,0.2)}.scroll-down-arrow{position:fixed;bottom:20px;left:20px;font-size:2rem;color:var(--color-text);background:var(--color-bg-secondary);border-radius:50%;padding:10px;z-index:1000;animation:float 1.5s ease-in-out infinite}@keyframes float{0%,100%{transform:translateY(0)}50%{transform:translateY(-10px)}}</style> <script>document.addEventListener("scroll",function(){const e=document.querySelector(".scroll-down-arrow"),o=document.documentElement.scrollHeight-window.innerHeight,n=window.scrollY;e.style.display=n>0&&n<o-50?"block":"none"}),document.querySelector(".scroll-down-arrow").addEventListener("click",function(e){e.preventDefault(),window.scrollBy({top:window.innerHeight,behavior:"smooth"})});</script> </div> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Sri Aditya Deevi. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js" integrity="sha256-rjmgmaB99riUNcdlrDtcAiwtLIojSxNyUFdl+Qh+rB4=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-publications",title:"publications",description:"Publications in reversed chronological order",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-projects",title:"projects",description:"",section:"Navigation",handler:()=>{window.location.href="/projects/"}},{id:"nav-awards",title:"awards",description:"",section:"Navigation",handler:()=>{window.location.href="/awards/"}},{id:"nav-certifications",title:"certifications",description:"",section:"Navigation",handler:()=>{window.location.href="/certifications/"}},{id:"nav-gallery",title:"gallery",description:"",section:"Navigation",handler:()=>{window.location.href="/gallery/"}},{id:"post-google-gemini-updates-flash-1-5-gemma-2-and-project-astra",title:'Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra <svg width="1.2rem" height="1.2rem" top=".5rem" viewBox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg>',description:"We\u2019re sharing updates across our Gemini family of models and a glimpse of Project Astra, our vision for the future of AI assistants.",section:"Posts",handler:()=>{window.open("https://blog.google/technology/ai/google-gemini-update-flash-ai-assistant-io-2024/","_blank")}},{id:"post-a-post-with-tabs",title:"a post with tabs",description:"this is what included tabs in a post could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/tabs/"}},{id:"post-a-post-with-typograms",title:"a post with typograms",description:"this is what included typograms code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/typograms/"}},{id:"post-a-post-that-can-be-cited",title:"a post that can be cited",description:"this is what a post that can be cited looks like",section:"Posts",handler:()=>{window.location.href="/blog/2024/post-citation/"}},{id:"post-a-post-with-pseudo-code",title:"a post with pseudo code",description:"this is what included pseudo code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/pseudocode/"}},{id:"post-a-post-with-code-diff",title:"a post with code diff",description:"this is how you can display code diffs",section:"Posts",handler:()=>{window.location.href="/blog/2024/code-diff/"}},{id:"post-a-post-with-advanced-image-components",title:"a post with advanced image components",description:"this is what advanced image components could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/advanced-images/"}},{id:"post-a-post-with-vega-lite",title:"a post with vega lite",description:"this is what included vega lite code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/vega-lite/"}},{id:"post-a-post-with-geojson",title:"a post with geojson",description:"this is what included geojson code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/geojson-map/"}},{id:"post-a-post-with-echarts",title:"a post with echarts",description:"this is what included echarts code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/echarts/"}},{id:"post-a-post-with-chart-js",title:"a post with chart.js",description:"this is what included chart.js code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/chartjs/"}},{id:"post-a-post-with-tikzjax",title:"a post with TikZJax",description:"this is what included TikZ code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2023/tikzjax/"}},{id:"post-a-post-with-bibliography",title:"a post with bibliography",description:"an example of a blog post with bibliography",section:"Posts",handler:()=>{window.location.href="/blog/2023/post-bibliography/"}},{id:"post-a-post-with-jupyter-notebook",title:"a post with jupyter notebook",description:"an example of a blog post with jupyter notebook",section:"Posts",handler:()=>{window.location.href="/blog/2023/jupyter-notebook/"}},{id:"post-a-post-with-custom-blockquotes",title:"a post with custom blockquotes",description:"an example of a blog post with custom blockquotes",section:"Posts",handler:()=>{window.location.href="/blog/2023/custom-blockquotes/"}},{id:"post-a-post-with-table-of-contents-on-a-sidebar",title:"a post with table of contents on a sidebar",description:"an example of a blog post with table of contents on a sidebar",section:"Posts",handler:()=>{window.location.href="/blog/2023/sidebar-table-of-contents/"}},{id:"post-a-post-with-audios",title:"a post with audios",description:"this is what included audios could look like",section:"Posts",handler:()=>{window.location.href="/blog/2023/audios/"}},{id:"post-a-post-with-videos",title:"a post with videos",description:"this is what included videos could look like",section:"Posts",handler:()=>{window.location.href="/blog/2023/videos/"}},{id:"post-displaying-beautiful-tables-with-bootstrap-tables",title:"displaying beautiful tables with Bootstrap Tables",description:"an example of how to use Bootstrap Tables",section:"Posts",handler:()=>{window.location.href="/blog/2023/tables/"}},{id:"post-a-post-with-table-of-contents",title:"a post with table of contents",description:"an example of a blog post with table of contents",section:"Posts",handler:()=>{window.location.href="/blog/2023/table-of-contents/"}},{id:"post-a-post-with-giscus-comments",title:"a post with giscus comments",description:"an example of a blog post with giscus comments",section:"Posts",handler:()=>{window.location.href="/blog/2022/giscus-comments/"}},{id:"post-displaying-external-posts-on-your-al-folio-blog",title:'Displaying External Posts on Your al-folio Blog <svg width="1.2rem" height="1.2rem" top=".5rem" viewBox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg>',description:"",section:"Posts",handler:()=>{window.open("https://medium.com/@al-folio/displaying-external-posts-on-your-al-folio-blog-b60a1d241a0a?source=rss-17feae71c3c4------2","_blank")}},{id:"post-a-post-with-redirect",title:"a post with redirect",description:"you can also redirect to assets like pdf",section:"Posts",handler:()=>{window.location.href="/assets/pdf/example_pdf.pdf"}},{id:"post-a-post-with-diagrams",title:"a post with diagrams",description:"an example of a blog post with diagrams",section:"Posts",handler:()=>{window.location.href="/blog/2021/diagrams/"}},{id:"post-a-distill-style-blog-post",title:"a distill-style blog post",description:"an example of a distill-style blog post and main elements",section:"Posts",handler:()=>{window.location.href="/blog/2021/distill/"}},{id:"post-a-post-with-github-metadata",title:"a post with github metadata",description:"a quick run down on accessing github metadata.",section:"Posts",handler:()=>{window.location.href="/blog/2020/github-metadata/"}},{id:"post-a-post-with-twitter",title:"a post with twitter",description:"an example of a blog post with twitter",section:"Posts",handler:()=>{window.location.href="/blog/2020/twitter/"}},{id:"post-a-post-with-disqus-comments",title:"a post with disqus comments",description:"an example of a blog post with disqus comments",section:"Posts",handler:()=>{window.location.href="/blog/2015/disqus-comments/"}},{id:"post-a-post-with-math",title:"a post with math",description:"an example of a blog post with some math",section:"Posts",handler:()=>{window.location.href="/blog/2015/math/"}},{id:"post-a-post-with-code",title:"a post with code",description:"an example of a blog post with some code",section:"Posts",handler:()=>{window.location.href="/blog/2015/code/"}},{id:"post-a-post-with-images",title:"a post with images",description:"this is what included images could look like",section:"Posts",handler:()=>{window.location.href="/blog/2015/images/"}},{id:"post-a-post-with-formatting-and-links",title:"a post with formatting and links",description:"march &amp; april, looking forward to summer",section:"Posts",handler:()=>{window.location.href="/blog/2015/formatting-and-links/"}},{id:"news-presented-our-paper-lt-a-href-quot-https-www-sriadityadeevi-com-assets-pdf-ldsim-poster-pdf-quot-gt-laser-diode-motion-simulator-extending-the-capabilities-of-hardware-in-loop-space-rendezvous-testing-lt-a-gt-at-the-lt-a-href-quot-https-advancesinrobotics-com-2025-quot-gt-advances-in-robotics-air-2025-lt-a-gt-conference-organized-by-lt-a-href-quot-https-www-iitj-ac-in-quot-gt-iit-jodhpur-lt-a-gt",title:"Presented our paper, &lt;a href=&quot;https://www.sriadityadeevi.com/assets/pdf/ldsim_poster.pdf&quot;&gt;Laser Diode Motion Simulator: Extending the capabilities of Hardware-in-Loop Space Rendezvous Testing&lt;/a&gt;, at the &lt;a href=&quot;https://advancesinrobotics.com/2025/&quot;&gt;Advances in Robotics (AIR) 2025&lt;/a&gt; conference organized by &lt;a href=&quot;https://www.iitj.ac.in/&quot;&gt;IIT Jodhpur&lt;/a&gt;.",description:"",section:"News"},{id:"news-led-our-team-to-a-runner-up-finish-by-designing-robust-architectures-for-extraterrestrial-surface-navigation-as-a-part-of-the-training-programme-on-advanced-topics-in-robotics-organized-by-lt-a-href-quot-https-www-ursc-gov-in-quot-gt-u-r-rao-satellite-centre-lt-a-gt",title:"Led our team to a runner-up finish by designing Robust Architectures for Extraterrestrial Surface Navigation as a part of the Training Programme on Advanced Topics in Robotics organized by &lt;a href=&quot;https://www.ursc.gov.in/&quot;&gt;U.R. Rao Satellite Centre&lt;/a&gt;.",description:"",section:"News"},{id:"news-our-paper-lt-a-href-quot-https-ieeexplore-ieee-org-document-10857490-quot-gt-efficient-self-supervised-neural-architecture-search-lt-a-gt-published-in-the-proceedings-of-lt-a-href-quot-http-imcom-org-quot-gt-international-conference-on-ubiquitous-information-management-and-communication-imcom-2025-lt-a-gt",title:"Our paper, &lt;a href=&quot;https://ieeexplore.ieee.org/document/10857490&quot;&gt;Efficient Self-Supervised Neural Architecture Search&lt;/a&gt; published in the Proceedings of &lt;a href=&quot;http://imcom.org/&quot;&gt;International Conference on Ubiquitous Information Management and Communication (IMCOM) 2025&lt;/a&gt;.",description:"",section:"News"},{id:"news-won-the-ai-ml-challenge-organized-at-lt-a-href-quot-https-www-ursc-gov-in-quot-gt-u-r-rao-satellite-centre-lt-a-gt-competing-with-over-250-scientists",title:"Won the AI/ML challenge organized at &lt;a href=&quot;https://www.ursc.gov.in/&quot;&gt;U.R. Rao Satellite Centre&lt;/a&gt;, competing with over 250 scientists.",description:"",section:"News"},{id:"news-presented-interactive-demos-showcasing-our-research-group-s-work-to-school-students-on-lt-a-href-quot-https-www-isro-gov-in-nspd2024-quot-gt-national-space-day-lt-a-gt",title:"Presented interactive demos showcasing our research group\u2019s work to school students on &lt;a href=&quot;https://www.isro.gov.in/NSPD2024/&quot;&gt;National Space Day&lt;/a&gt;.",description:"",section:"News"},{id:"news-joined-lt-a-href-quot-https-www-ursc-gov-in-quot-gt-u-r-rao-satellite-centre-lt-a-gt-as-a-scientist-engineer-sc-in-the-mission-simulation-group",title:"Joined &lt;a href=&quot;https://www.ursc.gov.in&quot;&gt;U.R. Rao Satellite Centre&lt;/a&gt; as a Scientist/Engineer - \u2018SC\u2019 in the Mission Simulation Group.",description:"",section:"News"},{id:"news-our-paper-lt-a-href-quot-https-openaccess-thecvf-com-content-wacv2024-html-deevi-rgb-x-object-detection-via-scene-specific-fusion-modules-wacv-2024-paper-html-quot-gt-rgb-x-object-detection-via-scene-specific-fusion-modules-lt-a-gt-published-in-the-proceedings-of-the-ieee-cvf-winter-conference-on-applications-of-computer-vision-wacv-2024",title:"Our paper, &lt;a href=&quot;https://openaccess.thecvf.com/content/WACV2024/html/Deevi_RGB-X_Object_Detection_via_Scene-Specific_Fusion_Modules_WACV_2024_paper.html&quot;&gt;RGB-X Object Detection via Scene-Specific Fusion Modules&lt;/a&gt;, published in the Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV), 2024.",description:"",section:"News"},{id:"news-completed-graduate-research-internship-at-lt-a-href-quot-https-www-jpl-nasa-gov-quot-gt-nasa-s-jet-propulsion-laboratory-lt-a-gt",title:"Completed Graduate Research Internship at &lt;a href=&quot;https://www.jpl.nasa.gov&quot;&gt;NASA\u2019s Jet Propulsion Laboratory&lt;/a&gt;.",description:"",section:"News"},{id:"projects-self-untangling-robotic-snake-arm-with-dynamic-obstacle-avoidance",title:"Self Untangling Robotic Snake Arm with Dynamic Obstacle Avoidance",description:"",section:"Projects",handler:()=>{window.location.href="/projects/0_project/"}},{id:"projects-iot-controlled-smart-home",title:"IoT controlled Smart Home",description:"",section:"Projects",handler:()=>{window.location.href="/projects/10_project/"}},{id:"projects-voice-controlled-robot",title:"Voice Controlled Robot",description:"",section:"Projects",handler:()=>{window.location.href="/projects/11_project/"}},{id:"projects-fiscal-responsibility-index",title:"Fiscal Responsibility Index",description:"",section:"Projects",handler:()=>{window.location.href="/projects/12_project/"}},{id:"projects-fire-alarm",title:"Fire Alarm",description:"",section:"Projects",handler:()=>{window.location.href="/projects/13_project/"}},{id:"projects-rrt-based-motion-planner-for-non-holonomic-mobile-robots",title:"RRT Based Motion Planner for Non-Holonomic Mobile Robots",description:"",section:"Projects",handler:()=>{window.location.href="/projects/1_project/"}},{id:"projects-non-holonomic-rrt-with-dynamic-replanning-and-obstacle-mapping",title:"Non Holonomic RRT with Dynamic Replanning and Obstacle Mapping",description:"",section:"Projects",handler:()=>{window.location.href="/projects/2_project/"}},{id:"projects-atmospheric-parameter-forecasting-for-optical-channel-characterization",title:"Atmospheric Parameter Forecasting for Optical Channel Characterization",description:"",section:"Projects",handler:()=>{window.location.href="/projects/2_project_1/"}},{id:"projects-rgb-x-object-detection-via-scene-specific-fusion-modules",title:"RGB-X Object Detection via Scene-Specific Fusion Modules",description:"",section:"Projects",handler:()=>{window.location.href="/projects/3_project/"}},{id:"projects-autonomous-robotic-grasping",title:"Autonomous Robotic Grasping",description:"",section:"Projects",handler:()=>{window.location.href="/projects/4_project/"}},{id:"projects-efficient-self-supervised-neural-architecture-search",title:"Efficient Self-Supervised Neural Architecture Search",description:"",section:"Projects",handler:()=>{window.location.href="/projects/5_project/"}},{id:"projects-pose-estimation-for-autonomous-robotic-grasping",title:"Pose Estimation for Autonomous Robotic Grasping",description:"",section:"Projects",handler:()=>{window.location.href="/projects/6_project/"}},{id:"projects-scene-text-recognition",title:"Scene Text Recognition",description:"",section:"Projects",handler:()=>{window.location.href="/projects/7_project/"}},{id:"projects-automatic-speaker-recognition-system",title:"Automatic Speaker Recognition System",description:"",section:"Projects",handler:()=>{window.location.href="/projects/7_project_1/"}},{id:"projects-swadeshi-microprocessor-challenge",title:"Swadeshi Microprocessor Challenge",description:"",section:"Projects",handler:()=>{window.location.href="/projects/7_project_2/"}},{id:"projects-anomaly-detection-in-satellite-telemetry",title:"Anomaly Detection in Satellite Telemetry",description:"",section:"Projects",handler:()=>{window.location.href="/projects/8_project/"}},{id:"projects-ecg-beat-classification",title:"ECG Beat Classification",description:"",section:"Projects",handler:()=>{window.location.href="/projects/9_project/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%64%73%72%69%61%64%69%74%79%61%39%39%39@%67%6D%61%69%6C.%63%6F%6D","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=6XKjIWUAAAAJ","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/dsriaditya999","_blank")}},{id:"socials-linkedin",title:"LinkedIn",section:"Socials",handler:()=>{window.open("https://www.linkedin.com/in/sri-aditya-deevi","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js"></script> </body> </html>