<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> publications | Sri Aditya Deevi </title> <meta name="author" content="Sri Aditya Deevi"> <meta name="description" content="Publications in reversed chronological order"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%A4%96&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://dsriaditya999.github.io/publications/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Sri Aditya</span> Deevi </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">publications <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/awards/">awards </a> </li> <li class="nav-item "> <a class="nav-link" href="/certifications/">certifications </a> </li> <li class="nav-item "> <a class="nav-link" href="/gallery/">gallery </a> </li> <li class="nav-item"> <a class="nav-link" href="/assets/pdf/SriAdityaDeevi_Resume_06Oct2025.pdf" target="_blank" rel="noopener noreferrer">cv <span class="sr-only">(current)</span> </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">publications</h1> <p class="post-description">Publications in reversed chronological order</p> </header> <article> <div class="publications"> <h2 class="bibliography">2026</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/lowthrust-480.webp 480w,/assets/img/publication_preview/lowthrust-800.webp 800w,/assets/img/publication_preview/lowthrust-1400.webp 1400w," sizes="500px" type="image/webp"></source> <img src="/assets/img/publication_preview/lowthrust.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="lowthrust.gif" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Deevi_2025_lowthrust" class="col-sm-8"> <div class="title">Adaptive Q-law Control for Closed-loop Electric Propulsion Orbit Transfer</div> <div class="author"> Suraj Kumar, <em>Sri Aditya Deevi</em>, Aditya Rallapalli , and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Bharat Kumar GVP' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>Accepted in American Institute of Aeronautics and Astronautics (AIAA) Scitech Forum</em>, Jan 2026 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> </div> <div class="abstract hidden"> <p align="left">This paper proposes an adaptive Q-law controller for closed-loop low-thrust, many-revolution orbit transfers. A Lyapunov-based modification of the classical Q-law controller is introduced to ensure closed-loop stability and real-time implementability for GTO-GEO transfer. To optimize the control gains for minimum-time transfers, a novel simulation-based two-stage hybrid optimization framework is developed. Unlike the classical Q-law with fixed control gains, the proposed approach makes the control gains explicitly state- and time-dependent by parameterizing them with a neural network. In the first, offline stage, Sobol-sequenced random samples of the network weights and their corresponding orbit transfer times are used to compute the empirical mean and a regularized covariance of the top performers. This distribution then warm-starts the gradient-free Covariance Matrix Adaptation Evolution Strategy (CMA-ES) optimizer, directing its search toward the most promising regions. The second, online stage employs an optimization loop, where the archive-seeded CMA-ES iteratively samples candidate network weights, evaluates them on the high-fidelity simulator, and updates its search distribution until convergence. Finally, the optimized neural controller is distilled into a polynomial function approximator for onboard implementation.</p> </div> </div> </div> </li></ol> <h2 class="bibliography">2025</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/essnas-480.webp 480w,/assets/img/publication_preview/essnas-800.webp 800w,/assets/img/publication_preview/essnas-1400.webp 1400w," sizes="500px" type="image/webp"></source> <img src="/assets/img/publication_preview/essnas.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="essnas.gif" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Deevi_2025_IMCOM" class="col-sm-8"> <div class="title">Efficient Self-Supervised Neural Architecture Search</div> <div class="author"> <em>Sri Aditya Deevi</em> , Asish Kumar Mishra, <a href="https://scholar.google.com/citations?hl=en&amp;user=N-bWm_wAAAAJ&amp;view_op=list_works&amp;sortby=pubdate" rel="external nofollow noopener" target="_blank">Deepak Mishra</a> , and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Ravikumar L., Bharat Kumar GVP, Murali Krishna Bhagavan G.' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>Proceedings of International Conference on Ubiquitous Information Management and Communication (IMCOM)</em>, Feb 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="https://ieeexplore.ieee.org/document/10857490" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://youtu.be/r_Wl1JFt4zY" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> <a href="/assets/pdf/esnas_slides.pdf" class="btn btn-sm z-depth-0" role="button">Slides</a> </div> <div class="abstract hidden"> <p align="left">Deep Neural Networks (DNNs) have successfully demonstrated superior performance on many tasks across multiple domains. Their success is made possible by expert practitioners’ careful design of neural architectures. This manual handcrafted design requires a colossal number of computational resources, time, and memory to arrive at an optimal architecture. Automated Neural Architecture Search (NAS) is a promising area to explore to overcome these issues. However, optimizing a network for a job is a tedious task that requires lengthy search time, high processor needs, and a thorough examination of enormous possibilities. The need of the hour is to develop a strategy that saves time while maintaining an excellent level of accuracy. In this paper, we design, explore, and experiment with various differentiable NAS methods which are memory, time, and compute efficient. We also explore the role and efficacy of self-supervision to guide the search for optimal architectures. Self-supervision offers numerous advantages such as facilitating the use of unlabelled data and making the “learning” non-task specific, thereby improving transfer to other tasks. To study the inclusion of self-supervision into the search process, we propose a simple loss function consisting of a convex combination of supervised cross-entropy loss and self-supervision loss. In addition, we carried out various analyses to characterize the performance of different approaches considered in this paper. The inspection of results obtained from various experiments on CIFAR-10 reveals that the proposed methodology balances time and accuracy while staying as near as possible to the state-of-the-art results.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/ldsim-480.webp 480w,/assets/img/publication_preview/ldsim-800.webp 800w,/assets/img/publication_preview/ldsim-1400.webp 1400w," sizes="500px" type="image/webp"></source> <img src="/assets/img/publication_preview/ldsim.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="ldsim.gif" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Deevi_2025_ldsim" class="col-sm-8"> <div class="title">Laser Diode Motion Simulator: Extending the capabilities of Hardware-in-Loop Space Rendezvous Testing</div> <div class="author"> <em>Sri Aditya Deevi</em>, Aakash Chaudhary, Samuel Lakkoju , and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Yajur Kumar, Murali Krishna Bhagavan G., Ravikumar L.' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>Accepted in Advances in Robotics (AIR) Conference</em>, Jul 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="/assets/pdf/ldsim_poster.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a> </div> <div class="abstract hidden"> <p align="left">In the realm of space exploration, the precision of spacecraft rendezvous operations is paramount. Traditional Hardware-in-the-Loop Simulation (HILS) facilities often encounter constraints due to limited track lengths, which can impede the accurate emulation of relative movements between spacecraft. To address this challenge, we have enhanced our HILS Space Rendezvous Robotic Testbed by integrating a Laser Diode (LD) Motion Simulator. The robotic testbed features two industrial robots—one equipped with photodetectors and the other with laser diodes—to replicate the relative motion between chaser and target spacecraft during proximity operations. To further augment this relative motion, the LDs are mounted on a motion mechanism. By physically moving the LDs, we can effectively simulate the dynamics of two spacecraft over extended distances without requiring large physical tracks. Preliminary experiments, encompassing both simulation and hardware implementations, have demonstrated the efficacy of this approach in overcoming spatial limitations and enhancing the realism of rendezvous testing scenarios.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/nerf-480.webp 480w,/assets/img/publication_preview/nerf-800.webp 800w,/assets/img/publication_preview/nerf-1400.webp 1400w," sizes="500px" type="image/webp"></source> <img src="/assets/img/publication_preview/nerf.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="nerf.gif" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Deevi_2025_NERF" class="col-sm-8"> <div class="title">Neural Radiance Fields in Space Applications: A Comprehensive Review</div> <div class="author"> Abraham Paul, <em>Sri Aditya Deevi</em>, Aakash Chaudhary , and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Ravikumar L., Anoop G.L, Ganesh Kumar R.' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>International Journal of Advanced Research (IJAR)</em>, Mar 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="https://dx.doi.org/10.21474/IJAR01/20596" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p align="left">Neural Radiance Fields (NeRF) have emerged as a powerful deep learning technique, revolutionizing the representation and rendering of 3D scenes. Although originally developed for computer vision and graphics applications, the potential of NeRF is increasingly being recognized in space-related fields. This paper provides a comprehensive review of the applications, advancements and challenges associated with the use of NeRF in space exploration, satellite imaging and remote sensing. We begin by introducing the foundational concepts of NeRF, including its architecture, underlying principles and computational requirements. We then explore how NeRF has been adapted and applied to space-specific challenges such as high-resolution 3D reconstruction of planetary surfaces, the visualization of satellite data and the enhancement of space mission planning. Furthermore, we discuss the integration of NeRF with other cutting-edge technologies like machine learning, autonomous systems and real-time rendering, highlighting the potential for future breakthroughs in space missions. Finally, we outline thecurrent limitations and open research questions, offering insights into the future directions of NeRF in space applications. This review aims to serve as a valuable resource for researchers and practitioners exploring the intersection of machine learning, computer graphics and space science.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/rsl-480.webp 480w,/assets/img/publication_preview/rsl-800.webp 800w,/assets/img/publication_preview/rsl-1400.webp 1400w," sizes="500px" type="image/webp"></source> <img src="/assets/img/publication_preview/rsl.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="rsl.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Deevi_2025_RSL" class="col-sm-8"> <div class="title">High Fidelity Hardware-in-Loop Simulation of Autonomous Spacecraft Rendezvous and Docking using Dual-Robot Platform on Track</div> <div class="author"> Ravikumar L., Samuel Lakkoju, Kartikeyan Bhanu , and <span class="more-authors" title="click to view 4 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '4 more authors' ? 'Sri Aditya Deevi, Aakash Chaudhary, Murali Krishna Bhagavan G., Sudhakar S.' : '4 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">4 more authors</span> </div> <div class="periodical"> <em>Submitted in 2025 International Conference on Space Robotics (iSpaRo)</em>, Dec 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> </div> <div class="abstract hidden"> <p align="left">In this paper, we present the Rendezvous Simulation Laboratory (RSL), a high‑fidelity hardware‑in‑the‑loop facility built around dual 6‑DoF robotic manipulators mounted on an 18 m linear track to emulate autonomous spacecraft rendezvous and docking. We demonstrate sub‑millimetre positioning accuracy and robust soft‑docking in closed‑loop tests under varying approach trajectories, lighting conditions, and communication delays. Finally, we validate navigation, guidance, and control algorithms for proximity operations in ISRO’s SPADEX mission through exhaustive ground verification and outline proposed extensions to RSL for future docking and on‑orbit servicing missions.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2024</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/rgb-x-object-detection-480.webp 480w,/assets/img/publication_preview/rgb-x-object-detection-800.webp 800w,/assets/img/publication_preview/rgb-x-object-detection-1400.webp 1400w," sizes="500px" type="image/webp"></source> <img src="/assets/img/publication_preview/rgb-x-object-detection.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="rgb-x-object-detection.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Deevi_2024_WACV" class="col-sm-8"> <div class="title">RGB-X Object Detection via Scene-Specific Fusion Modules</div> <div class="author"> <em>Sri Aditya Deevi</em>, Connor Lee, <a href="https://scholar.google.com/citations?hl=en&amp;user=mVY8wE8AAAAJ" rel="external nofollow noopener" target="_blank">Lu Gan</a> , and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Sushruth Nagesh, Gaurav Pandey, Soon-Jo Chung' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)</em>, Jan 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="https://openaccess.thecvf.com/content/WACV2024/html/Deevi_RGB-X_Object_Detection_via_Scene-Specific_Fusion_Modules_WACV_2024_paper.html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://github.com/dsriaditya999/RGBXFusion" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="/assets/pdf/RGB_X_Object_Detection_via_Scene_Specific_Fusion_Modules__Poster.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a> <a href="/assets/pdf/wacv_rgbx_video.pdf" class="btn btn-sm z-depth-0" role="button">Slides</a> </div> <div class="abstract hidden"> <p align="left">Multimodal deep sensor fusion has the potential to enable autonomous vehicles to visually understand their surrounding environments in all weather conditions. However, existing deep sensor fusion methods usually employ convoluted architectures with intermingled multimodal features, requiring large coregistered multimodal datasets for training. In this work, we present an efficient and modular RGB-X fusion network that can leverage and fuse pretrained single-modal models via scene-specific fusion modules, thereby enabling joint input-adaptive network architectures to be created using small, coregistered multimodal datasets. Our experiments demonstrate the superiority of our method compared to existing works on RGB-thermal and RGB-gated datasets, performing fusion using only a small amount of additional parameters. Our code is available at https://github.com/dsriaditya999/RGBXFusion.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/satpose-480.webp 480w,/assets/img/publication_preview/satpose-800.webp 800w,/assets/img/publication_preview/satpose-1400.webp 1400w," sizes="500px" type="image/webp"></source> <img src="/assets/img/publication_preview/satpose.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="satpose.gif" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Deevi_2024_satpose" class="col-sm-8"> <div class="title">Effective Landmark Regression using Attention-based HRNet for Satellite Pose Estimation</div> <div class="author"> Abraham Paul, Anoop G.L, Ganesh Kumar R. , and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Aryan Singh, Sri Aditya Deevi, Ravikumar L.' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>Proceedings of South Asian Research Center (SARC) International Conference</em>, Nov 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="https://digitalxplore.org/proceeding.php?pid=2707" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/satpose_ppt.pdf" class="btn btn-sm z-depth-0" role="button">Slides</a> </div> <div class="abstract hidden"> <p align="left">For many space missions, it is important to estimate the position and orientation of the satellite for operations such as docking and debris removal. It involves the following stages of object detection, landmark regression and pose estimation. For objection detection, we used Faster-RCNN with HRNet as the backbone, the landmark regression part is done using AHRNet architecture, the pose estimation is implemented using PnP algorithm. Firstly, each image was labeled for object detection with bounding boxes around the satellite images created in Blender which were then used to train for satellite detection. An AHRNet was further trained for landmark regression using a 4fold cross-validation approach which involved splitting the dataset into multiple training and validation sets to enhance the Intersection over Union (IoU) metric. After the landmark regression provided a 2D projection of 3D ground truth points, the PnP algorithm was then used for pose estimation. To improve pose estimation accuracy, we integrated solvePnP with an iterator argument utilizing the Levenberg-Marquardt (LM) method to reduce noise and outliers. Our methodology significantly enhances the precision and efficiency of the translation and rotation error of the satellite during the docking processes offering a viable solution for autonomous space missions with potential for future improvements in domain adaptability through the development of unsupervised domain adaptation models. The results of the landmark regression using AHRNet shows an improved reprojection error, orientation and translation errors.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2022</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/success_pe-480.webp 480w,/assets/img/publication_preview/success_pe-800.webp 800w,/assets/img/publication_preview/success_pe-1400.webp 1400w," sizes="500px" type="image/webp"></source> <img src="/assets/img/publication_preview/success_pe.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="success_pe.gif" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="deevi2022expeditious" class="col-sm-8"> <div class="title">Expeditious object pose estimation for autonomous robotic grasping</div> <div class="author"> <em>Sri Aditya Deevi</em>, and <a href="https://scholar.google.com/citations?hl=en&amp;user=N-bWm_wAAAAJ&amp;view_op=list_works&amp;sortby=pubdate" rel="external nofollow noopener" target="_blank">Deepak Mishra</a> </div> <div class="periodical"> <em>International Conference on Computer Vision and Image Processing</em>, Nov 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="https://link.springer.com/chapter/10.1007/978-3-031-31417-9_2" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://youtu.be/fjW7IAH3shs" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> <a href="/assets/pdf/PPT_CVIP%202022.pdf" class="btn btn-sm z-depth-0" role="button">Slides</a> </div> <div class="abstract hidden"> <p align="left">The ability of a robot to sense and “perceive" its surroundings to interact and influence various objects of interest by grasping them, using vision-based sensors is the main principle behind vision based Autonomous Robotic Grasping. To realise this task of autonomous object grasping, one of the critical sub-tasks is the 6D Pose Estimation of a known object of interest from sensory data in a given environment. The sensory data can include RGB images and data from depth sensors, but determining the object’s pose using only a single RGB image is cost-effective and highly desirable in many applications. In this work, we develop a series of convolutional neural network-based pose estimation models without post-refinement stages, designed to achieve high accuracy on relevant metrics for efficiently estimating the 6D pose of an object, using only a single RGB image. The designed models are incorporated into an end-to-end pose estimation pipeline based on Unity and ROS Noetic, where a UR3 Robotic Arm is deployed in a simulated pick-and-place task. The pose estimation performance of the different models is compared and analysed in both same-environment and cross-environment cases utilising synthetic RGB data collected from cluttered and simple simulation scenes constructed in Unity Environment. In addition, the developed models achieved high Average Distance (ADD) metric scores greater than 93% for most of the real-life objects tested in the LINEMOD dataset and can be integrated seamlessly with any robotic arm for estimating 6D pose from only RGB data, making our method effective, efficient and generic.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/data_iot-480.webp 480w,/assets/img/publication_preview/data_iot-800.webp 800w,/assets/img/publication_preview/data_iot-1400.webp 1400w," sizes="500px" type="image/webp"></source> <img src="/assets/img/publication_preview/data_iot.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="data_iot.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="deevi2022data" class="col-sm-8"> <div class="title">Data Summarization in Internet of Things</div> <div class="author"> <em>Sri Aditya Deevi</em>, and BS Manoj </div> <div class="periodical"> <em>SN Computer Science</em>, May 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="https://link.springer.com/article/10.1007/s42979-022-01188-9" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p align="left">With recent advances in the field of Internet of Things (IoT), the quantity of data being generated by various sensors and Internet users has increased dramatically which in turn has skyrocketed the need for efficient data compression methods. Data summarization is an efficient and effective technique for data compression that can generate a brief and succinct summary from typically larger quantities of data in an intelligent and highly useful manner, which can be done at various levels of abstraction. The impact of using such a technique in large IoT networks can be significantly advantageous in terms of reduction in the processing time, overall computation, data storage-transmission requirements, energy consumption, and possible workload on IoT users. In this work, a review of existing methods for data summarization techniques at various levels of abstraction of typical IoT networks are discussed. The levels of categorization that are considered are Low-level and High-level. Under each abstraction level, various techniques are further classified while briefly describing their essential characters.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2021</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/temp-480.webp 480w,/assets/img/publication_preview/temp-800.webp 800w,/assets/img/publication_preview/temp-1400.webp 1400w," sizes="500px" type="image/webp"></source> <img src="/assets/img/publication_preview/temp.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="temp.gif" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="deevi2021heartnetec" class="col-sm-8"> <div class="title">HeartNetEC: a deep representation learning approach for ECG beat classification</div> <div class="author"> <em>Sri Aditya Deevi</em>, Christina Perinbam Kaniraja, Vani Devi Mani , and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Deepak Mishra, Shaik Ummar, Cejoy Satheesh' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>Biomedical Engineering Letters</em>, Feb 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="https://link.springer.com/article/10.1007/s13534-021-00184-x" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://dsriaditya999.github.io/ecgheartnetec.github.io/" class="btn btn-sm z-depth-0" role="button">Code</a> </div> <div class="abstract hidden"> <p align="left">One of the most crucial and informative tools available at the disposal of a Cardiologist for examining the condition of a patient’s cardiovascular system is the electrocardiogram (ECG/EKG). A major reason behind the need for accurate reconstruction of ECG comes from the fact that the shape of ECG tracing is very crucial for determining the health condition of an individual. Whether the patient is prone to or diagnosed with cardiovascular diseases (CVDs), this information can be gathered through examination of ECG signal. Among various other methods, one of the most helpful methods in identifying cardiac abnormalities is a beat-wise categorization of a patient’s ECG record. In this work, a highly efficient deep representation learning approach for ECG beat classification is proposed, which can significantly reduce the burden and time spent by a Cardiologist for ECG Analysis. This work consists of two sub-systems: denoising block and beat classification block. The initial block is a denoising block that acquires the ECG signal from the patient and denoises that. The next stage is the beat classification part. This processes the input ECG signal for finding out the different classes of beats in the ECG through an efficient algorithm. In both stages, deep learning-based methods have been employed for the purpose. Our proposed approach has been tested on PhysioNet’s MIT-BIH Arrhythmia Database, for beat-wise classification into ten important types of heartbeats. As per the results obtained, the proposed approach is capable of making meaningful predictions and gives superior results on relevant metrics.</p> </div> </div> </div> </li></ol> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Sri Aditya Deevi. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js" integrity="sha256-rjmgmaB99riUNcdlrDtcAiwtLIojSxNyUFdl+Qh+rB4=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-publications",title:"publications",description:"Publications in reversed chronological order",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-projects",title:"projects",description:"",section:"Navigation",handler:()=>{window.location.href="/projects/"}},{id:"nav-awards",title:"awards",description:"",section:"Navigation",handler:()=>{window.location.href="/awards/"}},{id:"nav-certifications",title:"certifications",description:"",section:"Navigation",handler:()=>{window.location.href="/certifications/"}},{id:"nav-gallery",title:"gallery",description:"",section:"Navigation",handler:()=>{window.location.href="/gallery/"}},{id:"post-google-gemini-updates-flash-1-5-gemma-2-and-project-astra",title:'Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra <svg width="1.2rem" height="1.2rem" top=".5rem" viewBox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg>',description:"We\u2019re sharing updates across our Gemini family of models and a glimpse of Project Astra, our vision for the future of AI assistants.",section:"Posts",handler:()=>{window.open("https://blog.google/technology/ai/google-gemini-update-flash-ai-assistant-io-2024/","_blank")}},{id:"post-a-post-with-tabs",title:"a post with tabs",description:"this is what included tabs in a post could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/tabs/"}},{id:"post-a-post-with-typograms",title:"a post with typograms",description:"this is what included typograms code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/typograms/"}},{id:"post-a-post-that-can-be-cited",title:"a post that can be cited",description:"this is what a post that can be cited looks like",section:"Posts",handler:()=>{window.location.href="/blog/2024/post-citation/"}},{id:"post-a-post-with-pseudo-code",title:"a post with pseudo code",description:"this is what included pseudo code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/pseudocode/"}},{id:"post-a-post-with-code-diff",title:"a post with code diff",description:"this is how you can display code diffs",section:"Posts",handler:()=>{window.location.href="/blog/2024/code-diff/"}},{id:"post-a-post-with-advanced-image-components",title:"a post with advanced image components",description:"this is what advanced image components could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/advanced-images/"}},{id:"post-a-post-with-vega-lite",title:"a post with vega lite",description:"this is what included vega lite code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/vega-lite/"}},{id:"post-a-post-with-geojson",title:"a post with geojson",description:"this is what included geojson code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/geojson-map/"}},{id:"post-a-post-with-echarts",title:"a post with echarts",description:"this is what included echarts code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/echarts/"}},{id:"post-a-post-with-chart-js",title:"a post with chart.js",description:"this is what included chart.js code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/chartjs/"}},{id:"post-a-post-with-tikzjax",title:"a post with TikZJax",description:"this is what included TikZ code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2023/tikzjax/"}},{id:"post-a-post-with-bibliography",title:"a post with bibliography",description:"an example of a blog post with bibliography",section:"Posts",handler:()=>{window.location.href="/blog/2023/post-bibliography/"}},{id:"post-a-post-with-jupyter-notebook",title:"a post with jupyter notebook",description:"an example of a blog post with jupyter notebook",section:"Posts",handler:()=>{window.location.href="/blog/2023/jupyter-notebook/"}},{id:"post-a-post-with-custom-blockquotes",title:"a post with custom blockquotes",description:"an example of a blog post with custom blockquotes",section:"Posts",handler:()=>{window.location.href="/blog/2023/custom-blockquotes/"}},{id:"post-a-post-with-table-of-contents-on-a-sidebar",title:"a post with table of contents on a sidebar",description:"an example of a blog post with table of contents on a sidebar",section:"Posts",handler:()=>{window.location.href="/blog/2023/sidebar-table-of-contents/"}},{id:"post-a-post-with-audios",title:"a post with audios",description:"this is what included audios could look like",section:"Posts",handler:()=>{window.location.href="/blog/2023/audios/"}},{id:"post-a-post-with-videos",title:"a post with videos",description:"this is what included videos could look like",section:"Posts",handler:()=>{window.location.href="/blog/2023/videos/"}},{id:"post-displaying-beautiful-tables-with-bootstrap-tables",title:"displaying beautiful tables with Bootstrap Tables",description:"an example of how to use Bootstrap Tables",section:"Posts",handler:()=>{window.location.href="/blog/2023/tables/"}},{id:"post-a-post-with-table-of-contents",title:"a post with table of contents",description:"an example of a blog post with table of contents",section:"Posts",handler:()=>{window.location.href="/blog/2023/table-of-contents/"}},{id:"post-a-post-with-giscus-comments",title:"a post with giscus comments",description:"an example of a blog post with giscus comments",section:"Posts",handler:()=>{window.location.href="/blog/2022/giscus-comments/"}},{id:"post-displaying-external-posts-on-your-al-folio-blog",title:'Displaying External Posts on Your al-folio Blog <svg width="1.2rem" height="1.2rem" top=".5rem" viewBox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg>',description:"",section:"Posts",handler:()=>{window.open("https://medium.com/@al-folio/displaying-external-posts-on-your-al-folio-blog-b60a1d241a0a?source=rss-17feae71c3c4------2","_blank")}},{id:"post-a-post-with-redirect",title:"a post with redirect",description:"you can also redirect to assets like pdf",section:"Posts",handler:()=>{window.location.href="/assets/pdf/example_pdf.pdf"}},{id:"post-a-post-with-diagrams",title:"a post with diagrams",description:"an example of a blog post with diagrams",section:"Posts",handler:()=>{window.location.href="/blog/2021/diagrams/"}},{id:"post-a-distill-style-blog-post",title:"a distill-style blog post",description:"an example of a distill-style blog post and main elements",section:"Posts",handler:()=>{window.location.href="/blog/2021/distill/"}},{id:"post-a-post-with-github-metadata",title:"a post with github metadata",description:"a quick run down on accessing github metadata.",section:"Posts",handler:()=>{window.location.href="/blog/2020/github-metadata/"}},{id:"post-a-post-with-twitter",title:"a post with twitter",description:"an example of a blog post with twitter",section:"Posts",handler:()=>{window.location.href="/blog/2020/twitter/"}},{id:"post-a-post-with-disqus-comments",title:"a post with disqus comments",description:"an example of a blog post with disqus comments",section:"Posts",handler:()=>{window.location.href="/blog/2015/disqus-comments/"}},{id:"post-a-post-with-math",title:"a post with math",description:"an example of a blog post with some math",section:"Posts",handler:()=>{window.location.href="/blog/2015/math/"}},{id:"post-a-post-with-code",title:"a post with code",description:"an example of a blog post with some code",section:"Posts",handler:()=>{window.location.href="/blog/2015/code/"}},{id:"post-a-post-with-images",title:"a post with images",description:"this is what included images could look like",section:"Posts",handler:()=>{window.location.href="/blog/2015/images/"}},{id:"post-a-post-with-formatting-and-links",title:"a post with formatting and links",description:"march &amp; april, looking forward to summer",section:"Posts",handler:()=>{window.location.href="/blog/2015/formatting-and-links/"}},{id:"news-presented-our-paper-lt-a-href-quot-https-www-sriadityadeevi-com-assets-pdf-ldsim-poster-pdf-quot-gt-laser-diode-motion-simulator-extending-the-capabilities-of-hardware-in-loop-space-rendezvous-testing-lt-a-gt-at-the-lt-a-href-quot-https-advancesinrobotics-com-2025-quot-gt-advances-in-robotics-air-2025-lt-a-gt-conference-organized-by-lt-a-href-quot-https-www-iitj-ac-in-quot-gt-iit-jodhpur-lt-a-gt",title:"Presented our paper, &lt;a href=&quot;https://www.sriadityadeevi.com/assets/pdf/ldsim_poster.pdf&quot;&gt;Laser Diode Motion Simulator: Extending the capabilities of Hardware-in-Loop Space Rendezvous Testing&lt;/a&gt;, at the &lt;a href=&quot;https://advancesinrobotics.com/2025/&quot;&gt;Advances in Robotics (AIR) 2025&lt;/a&gt; conference organized by &lt;a href=&quot;https://www.iitj.ac.in/&quot;&gt;IIT Jodhpur&lt;/a&gt;.",description:"",section:"News"},{id:"news-led-our-team-to-a-runner-up-finish-by-designing-robust-architectures-for-extraterrestrial-surface-navigation-as-a-part-of-the-training-programme-on-advanced-topics-in-robotics-organized-by-lt-a-href-quot-https-www-ursc-gov-in-quot-gt-u-r-rao-satellite-centre-lt-a-gt",title:"Led our team to a runner-up finish by designing Robust Architectures for Extraterrestrial Surface Navigation as a part of the Training Programme on Advanced Topics in Robotics organized by &lt;a href=&quot;https://www.ursc.gov.in/&quot;&gt;U.R. Rao Satellite Centre&lt;/a&gt;.",description:"",section:"News"},{id:"news-our-paper-lt-a-href-quot-https-ieeexplore-ieee-org-document-10857490-quot-gt-efficient-self-supervised-neural-architecture-search-lt-a-gt-published-in-the-proceedings-of-lt-a-href-quot-http-imcom-org-quot-gt-international-conference-on-ubiquitous-information-management-and-communication-imcom-2025-lt-a-gt",title:"Our paper, &lt;a href=&quot;https://ieeexplore.ieee.org/document/10857490&quot;&gt;Efficient Self-Supervised Neural Architecture Search&lt;/a&gt; published in the Proceedings of &lt;a href=&quot;http://imcom.org/&quot;&gt;International Conference on Ubiquitous Information Management and Communication (IMCOM) 2025&lt;/a&gt;.",description:"",section:"News"},{id:"news-won-the-ai-ml-challenge-organized-at-lt-a-href-quot-https-www-ursc-gov-in-quot-gt-u-r-rao-satellite-centre-lt-a-gt-competing-with-over-250-scientists",title:"Won the AI/ML challenge organized at &lt;a href=&quot;https://www.ursc.gov.in/&quot;&gt;U.R. Rao Satellite Centre&lt;/a&gt;, competing with over 250 scientists.",description:"",section:"News"},{id:"news-presented-interactive-demos-showcasing-our-research-group-s-work-to-school-students-on-lt-a-href-quot-https-www-isro-gov-in-nspd2024-quot-gt-national-space-day-lt-a-gt",title:"Presented interactive demos showcasing our research group\u2019s work to school students on &lt;a href=&quot;https://www.isro.gov.in/NSPD2024/&quot;&gt;National Space Day&lt;/a&gt;.",description:"",section:"News"},{id:"news-joined-lt-a-href-quot-https-www-ursc-gov-in-quot-gt-u-r-rao-satellite-centre-lt-a-gt-as-a-scientist-engineer-sc-in-the-mission-simulation-group",title:"Joined &lt;a href=&quot;https://www.ursc.gov.in&quot;&gt;U.R. Rao Satellite Centre&lt;/a&gt; as a Scientist/Engineer - \u2018SC\u2019 in the Mission Simulation Group.",description:"",section:"News"},{id:"news-our-paper-lt-a-href-quot-https-openaccess-thecvf-com-content-wacv2024-html-deevi-rgb-x-object-detection-via-scene-specific-fusion-modules-wacv-2024-paper-html-quot-gt-rgb-x-object-detection-via-scene-specific-fusion-modules-lt-a-gt-published-in-the-proceedings-of-the-ieee-cvf-winter-conference-on-applications-of-computer-vision-wacv-2024",title:"Our paper, &lt;a href=&quot;https://openaccess.thecvf.com/content/WACV2024/html/Deevi_RGB-X_Object_Detection_via_Scene-Specific_Fusion_Modules_WACV_2024_paper.html&quot;&gt;RGB-X Object Detection via Scene-Specific Fusion Modules&lt;/a&gt;, published in the Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV), 2024.",description:"",section:"News"},{id:"news-completed-graduate-research-internship-at-lt-a-href-quot-https-www-jpl-nasa-gov-quot-gt-nasa-s-jet-propulsion-laboratory-lt-a-gt",title:"Completed Graduate Research Internship at &lt;a href=&quot;https://www.jpl.nasa.gov&quot;&gt;NASA\u2019s Jet Propulsion Laboratory&lt;/a&gt;.",description:"",section:"News"},{id:"projects-self-untangling-robotic-snake-arm-with-dynamic-obstacle-avoidance",title:"Self Untangling Robotic Snake Arm with Dynamic Obstacle Avoidance",description:"",section:"Projects",handler:()=>{window.location.href="/projects/0_project/"}},{id:"projects-iot-controlled-smart-home",title:"IoT controlled Smart Home",description:"",section:"Projects",handler:()=>{window.location.href="/projects/10_project/"}},{id:"projects-voice-controlled-robot",title:"Voice Controlled Robot",description:"",section:"Projects",handler:()=>{window.location.href="/projects/11_project/"}},{id:"projects-fiscal-responsibility-index",title:"Fiscal Responsibility Index",description:"",section:"Projects",handler:()=>{window.location.href="/projects/12_project/"}},{id:"projects-fire-alarm",title:"Fire Alarm",description:"",section:"Projects",handler:()=>{window.location.href="/projects/13_project/"}},{id:"projects-rrt-based-motion-planner-for-non-holonomic-mobile-robots",title:"RRT Based Motion Planner for Non-Holonomic Mobile Robots",description:"",section:"Projects",handler:()=>{window.location.href="/projects/1_project/"}},{id:"projects-non-holonomic-rrt-with-dynamic-replanning-and-obstacle-mapping",title:"Non Holonomic RRT with Dynamic Replanning and Obstacle Mapping",description:"",section:"Projects",handler:()=>{window.location.href="/projects/2_project/"}},{id:"projects-atmospheric-parameter-forecasting-for-optical-channel-characterization",title:"Atmospheric Parameter Forecasting for Optical Channel Characterization",description:"",section:"Projects",handler:()=>{window.location.href="/projects/2_project_1/"}},{id:"projects-rgb-x-object-detection-via-scene-specific-fusion-modules",title:"RGB-X Object Detection via Scene-Specific Fusion Modules",description:"",section:"Projects",handler:()=>{window.location.href="/projects/3_project/"}},{id:"projects-autonomous-robotic-grasping",title:"Autonomous Robotic Grasping",description:"",section:"Projects",handler:()=>{window.location.href="/projects/4_project/"}},{id:"projects-efficient-self-supervised-neural-architecture-search",title:"Efficient Self-Supervised Neural Architecture Search",description:"",section:"Projects",handler:()=>{window.location.href="/projects/5_project/"}},{id:"projects-pose-estimation-for-autonomous-robotic-grasping",title:"Pose Estimation for Autonomous Robotic Grasping",description:"",section:"Projects",handler:()=>{window.location.href="/projects/6_project/"}},{id:"projects-scene-text-recognition",title:"Scene Text Recognition",description:"",section:"Projects",handler:()=>{window.location.href="/projects/7_project/"}},{id:"projects-automatic-speaker-recognition-system",title:"Automatic Speaker Recognition System",description:"",section:"Projects",handler:()=>{window.location.href="/projects/7_project_1/"}},{id:"projects-swadeshi-microprocessor-challenge",title:"Swadeshi Microprocessor Challenge",description:"",section:"Projects",handler:()=>{window.location.href="/projects/7_project_2/"}},{id:"projects-anomaly-detection-in-satellite-telemetry",title:"Anomaly Detection in Satellite Telemetry",description:"",section:"Projects",handler:()=>{window.location.href="/projects/8_project/"}},{id:"projects-ecg-beat-classification",title:"ECG Beat Classification",description:"",section:"Projects",handler:()=>{window.location.href="/projects/9_project/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%64%73%72%69%61%64%69%74%79%61%39%39%39@%67%6D%61%69%6C.%63%6F%6D","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=6XKjIWUAAAAJ","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/dsriaditya999","_blank")}},{id:"socials-linkedin",title:"LinkedIn",section:"Socials",handler:()=>{window.open("https://www.linkedin.com/in/sri-aditya-deevi","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js"></script> </body> </html>